{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# IDEAW Training on Google Colab\n","\n","This notebook trains IDEAW audio watermarking models using Colab's free GPU.\n","\n","**Before running:**\n","1. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n","2. Upload your data to Google Drive\n","3. Update the GitHub URL below with your repository"],"metadata":{"id":"header"}},{"cell_type":"markdown","source":["## 1. Setup Environment"],"metadata":{"id":"setup-header"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","%cd /content/drive/MyDrive/audio-watermarking-demo\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoRH8Wi3rz44","executionInfo":{"status":"ok","timestamp":1763289599184,"user_tz":-330,"elapsed":2026,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"8082e6ad-bed5-4a6b-e9a0-07cf0fd05a0d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/audio-watermarking-demo\n"]}]},{"cell_type":"code","source":["!git status\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGjpwQ2sx8fm","executionInfo":{"status":"ok","timestamp":1763290188117,"user_tz":-330,"elapsed":33977,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"581ff155-f49d-45ef-9ba9-b3ddae0a30dc"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["^C\n"]}]},{"cell_type":"code","source":["!git reset --soft HEAD~5\n"],"metadata":{"id":"ilKL3OpaznrZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add colab_notebooks/IDEAW_Training_Template.ipynb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrGMoGE9SF0B","executionInfo":{"status":"ok","timestamp":1763290407829,"user_tz":-330,"elapsed":170,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"b030619a-5227-44bc-8e9a-8af4468ba03b"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["warning: could not open directory 'research/IDEAW/colab_notebooks/': No such file or directory\n","fatal: pathspec 'colab_notebooks/IDEAW_Training_Template.ipynb' did not match any files\n"]}]},{"cell_type":"code","source":["!git commit -m \"directories added\"\n","\n","!git push origin main"],"metadata":{"id":"WpD__ypaSYsg"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65ee1c69","executionInfo":{"status":"ok","timestamp":1763290333052,"user_tz":-330,"elapsed":9605,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"0890cb7a-dc10-4775-dd49-05e4c84cd117"},"source":["!git status"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Refresh index: 100% (254/254), done.\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git restore --staged <file>...\" to unstage)\n","\t\u001b[32mmodified:   config.yaml\u001b[m\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   ../../colab_notebooks/IDEAW_Training_Template.ipynb\u001b[m\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"568db652"},"source":["### Diagnose slow `git status`\n","\n","To diagnose why `git status` is running slowly, let's check for a large number of untracked files. These are files that Git is aware of but not tracking."]},{"cell_type":"code","metadata":{"id":"1f612dc5","executionInfo":{"status":"ok","timestamp":1763290308436,"user_tz":-330,"elapsed":114,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}}},"source":["# List all untracked files (excluding those ignored by .gitignore)\n","!git ls-files --others --exclude-standard"],"execution_count":17,"outputs":[]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUtjV-i8SUmb","executionInfo":{"status":"ok","timestamp":1763290253092,"user_tz":-330,"elapsed":38572,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"c599c71d-54e6-4704-dd9b-a39a88c3a968"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["^C\n"]}]},{"cell_type":"code","source":["!git add colab_notebooks/IDEAW_Training_Template.ipynb\n","\n","# 4. Commit with a message\n","!git commit -m \"Running training loop\"\n","\n","# 5. Push to GitHub\n","!git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UTP6ZO0mzgnz","executionInfo":{"status":"ok","timestamp":1763241774930,"user_tz":-330,"elapsed":3674,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"d30e447d-2ca0-43c2-dbe7-9cfc94a9e12b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 486d4a1] Running training loop\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite colab_notebooks/IDEAW_Training_Template.ipynb (97%)\n","Enumerating objects: 7, done.\n","Counting objects: 100% (7/7), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (4/4), done.\n","Writing objects: 100% (4/4), 5.23 KiB | 382.00 KiB/s, done.\n","Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","remote: This repository moved. Please use the new location:\u001b[K\n","remote:   https://github.com/Abdullahyassir007/audio-watermarking-demo.git\u001b[K\n","To https://github.com/AbdullahYassir007/audio-watermarking-demo.git\n","   8dccca0..486d4a1  main -> main\n"]}]},{"cell_type":"code","source":["# !git checkout -- colab_notebooks/IDEAW_Training_Template.ipynb\n","!git pull origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wRxHZDvYsN8J","executionInfo":{"status":"ok","timestamp":1763289444604,"user_tz":-330,"elapsed":15347,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"a1ffbe44-696c-4889-d978-40c625e6f292"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["From https://github.com/AbdullahYassir007/audio-watermarking-demo\n"," * branch            main       -> FETCH_HEAD\n","Already up to date.\n"]}]},{"cell_type":"code","source":["# Abort the rebase\n","!git rebase --abort\n","\n","# Accept the remote version (my fix)\n","!git reset --hard origin/main\n","\n","# Now re-apply just your notebook and config changes\n","!git checkout HEAD~1 -- colab_notebooks/IDEAW_Training_Template.ipynb\n","!git checkout HEAD~1 -- research/IDEAW/config.yaml\n","\n","# Commit these changes\n","!git add colab_notebooks/IDEAW_Training_Template.ipynb research/IDEAW/config.yaml\n","!git commit -m \"Update Colab notebook and config for batch size 2\"\n","\n","# Push\n","!git push origin main\n"],"metadata":{"id":"XMgPpj37RhRd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763239781619,"user_tz":-330,"elapsed":3853,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"a96d8e8a-9396-4872-c8d3-599b113faf11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["HEAD is now at e0e1c82 Fix IDEAW PyTorch 2.x compatibility - STFT/iSTFT complex tensor handling\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n","Everything up-to-date\n"]}]},{"cell_type":"code","source":["\n","\n","# Set up paths\n","DRIVE_PATH = '/content/drive/MyDrive/audio-watermarking-demo'\n","DATA_PATH = f'{DRIVE_PATH}/Dataset'\n","CHECKPOINT_PATH = f'{DRIVE_PATH}/checkpoints'\n","RESULTS_PATH = f'{DRIVE_PATH}/results'\n","\n","# Create directories\n","import os\n","os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n","os.makedirs(RESULTS_PATH, exist_ok=True)\n","\n","print(\"‚úì Google Drive mounted\")\n","print(f\"‚úì Data path: {DATA_PATH}\")\n","print(f\"‚úì Checkpoint path: {CHECKPOINT_PATH}\")\n","print(f\"‚úì Results path: {RESULTS_PATH}\")"],"metadata":{"id":"mount-drive","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763289612829,"user_tz":-330,"elapsed":53,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"27375e40-62d6-4f7f-deb6-1de0570b9595"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Google Drive mounted\n","‚úì Data path: /content/drive/MyDrive/audio-watermarking-demo/Dataset\n","‚úì Checkpoint path: /content/drive/MyDrive/audio-watermarking-demo/checkpoints\n","‚úì Results path: /content/drive/MyDrive/audio-watermarking-demo/results\n"]}]},{"cell_type":"code","source":["# # Just install the missing packages, use Colab's existing PyTorch\n","# !pip install -q librosa==0.10.1 pydub PyYAML soundfile tqdm resampy\n","\n","# # Restart runtime\n","# import os\n","# os.kill(os.getpid(), 9)\n","\n"],"metadata":{"id":"1KKuaYkDBVnw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Install dependencies from IDEAW requirements\n","# !pip install -q -r research/IDEAW/requirements_colab.txt\n","# !pip install -q FrEIA\n","\n","# print(\"‚úì Dependencies installed\")"],"metadata":{"id":"install-deps","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763289624554,"user_tz":-330,"elapsed":8886,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"56cc7927-62ac-414b-bc23-f9c51fa2d151"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Dependencies installed\n"]}]},{"cell_type":"code","source":["# Check GPU availability\n","import torch\n","\n","print(f\"GPU Available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n","    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","    device = 'cuda'\n","else:\n","    print(\"‚ö†Ô∏è No GPU available, using CPU\")\n","    device = 'cpu'\n","\n","print(f\"\\n‚úì Using device: {device}\")"],"metadata":{"id":"check-gpu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763289632374,"user_tz":-330,"elapsed":2536,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"9b745fa1-1e2c-432d-b01b-7a460a8571b6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Available: True\n","GPU Name: Tesla T4\n","GPU Memory: 15.83 GB\n","\n","‚úì Using device: cuda\n"]}]},{"cell_type":"code","source":["# Verify installation\n","import torch\n","import librosa\n","import scipy\n","import numpy as np\n","import yaml\n","\n","print(\"=\" * 50)\n","print(\"ENVIRONMENT CHECK\")\n","print(\"=\" * 50)\n","print(f\"‚úì PyTorch: {torch.__version__}\")\n","print(f\"‚úì Librosa: {librosa.__version__}\")\n","print(f\"‚úì Scipy: {scipy.__version__}\")\n","print(f\"‚úì Numpy: {np.__version__}\")\n","print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n","print(\"=\" * 50)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0527lnznCL1i","executionInfo":{"status":"ok","timestamp":1763289634123,"user_tz":-330,"elapsed":33,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"a0befc47-60fc-40b4-ec42-1b052e1dbe4a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================================\n","ENVIRONMENT CHECK\n","==================================================\n","‚úì PyTorch: 2.8.0+cu126\n","‚úì Librosa: 0.10.1\n","‚úì Scipy: 1.11.4\n","‚úì Numpy: 1.26.4\n","‚úì CUDA available: True\n","‚úì GPU: Tesla T4\n","==================================================\n"]}]},{"cell_type":"markdown","source":["## 2. Load IDEAW Model"],"metadata":{"id":"load-model-header"}},{"cell_type":"code","source":["# # Import IDEAW\n","# import sys\n","# sys.path.insert(0, '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW')\n","\n","# from models.ideaw import IDEAW\n","\n","# # Configuration\n","# config_path = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/config.yaml'\n","# model_config_path = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/models/config.yaml'\n","\n","# # Initialize model\n","# ideaw = IDEAW(model_config_path, device)\n","# print(\"‚úì IDEAW model initialized\")\n","\n","# # Count parameters\n","# total_params = sum(p.numel() for p in ideaw.parameters())\n","# trainable_params = sum(p.numel() for p in ideaw.parameters() if p.requires_grad)\n","# print(f\"Total parameters: {total_params:,}\")\n","# print(f\"Trainable parameters: {trainable_params:,}\")"],"metadata":{"id":"load-model","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763238758256,"user_tz":-330,"elapsed":1715,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"9251dcd3-152d-483f-ad20-084007e25279"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì IDEAW model initialized\n","Total parameters: 8,425,023\n","Trainable parameters: 8,425,023\n"]}]},{"cell_type":"markdown","source":["## 3. Prepare Data"],"metadata":{"id":"data-header"}},{"cell_type":"code","source":["# ============================================\n","# PREPARE DATA FOR IDEAW TRAINING\n","# ============================================\n","import os\n","import pickle\n","import librosa\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Paths\n","DRIVE_PATH = '/content/drive/MyDrive/audio-watermarking-demo'\n","RAW_DATA_PATH = f'{DRIVE_PATH}/Dataset'\n","PROCESSED_DATA_PATH = '/content/processed_data'\n","CHECKPOINT_PATH = f'{DRIVE_PATH}/checkpoints'\n","RESULTS_PATH = f'{DRIVE_PATH}/results'\n","\n","# Parameters\n","MAX_FILES = 50  # Quick test with 50 files (set to None for all)\n","SAMPLE_RATE = 16000\n","SEGMENT_SAMPLES = 16000  # 1 second\n","\n","# Create directories\n","os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n","os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n","os.makedirs(f'{CHECKPOINT_PATH}/stage_I', exist_ok=True)\n","os.makedirs(f'{CHECKPOINT_PATH}/stage_II', exist_ok=True)\n","os.makedirs(RESULTS_PATH, exist_ok=True)\n","\n","print(\"=\"*50)\n","print(\"DATA PREPARATION\")\n","print(\"=\"*50)\n","\n","# Find audio files\n","if not os.path.exists(RAW_DATA_PATH):\n","    print(f\"‚ùå Data not found at {RAW_DATA_PATH}\")\n","else:\n","    audio_extensions = ['.mp3', '.wav', '.flac', '.m4a']\n","    audio_files = []\n","\n","    for root, dirs, files in os.walk(RAW_DATA_PATH):\n","        for file in files:\n","            if any(file.lower().endswith(ext) for ext in audio_extensions):\n","                audio_files.append(os.path.join(root, file))\n","\n","    print(f\"\\n‚úì Found {len(audio_files)} audio files\")\n","\n","    # Limit for testing\n","    if MAX_FILES and len(audio_files) > MAX_FILES:\n","        audio_files = audio_files[:MAX_FILES]\n","        print(f\"‚úì Using {MAX_FILES} files for quick test\")\n","\n","    if len(audio_files) > 0:\n","        print(f\"\\nProcessing {len(audio_files)} files...\")\n","        print(f\"Target: 16kHz, 1-second segments\")\n","\n","        data = []\n","\n","        for audio_path in tqdm(audio_files):\n","            try:\n","                # Load and resample\n","                audio, sr = librosa.load(audio_path, sr=SAMPLE_RATE, mono=True)\n","\n","                # Split into 1-second segments\n","                num_segments = int(len(audio) / SEGMENT_SAMPLES)\n","\n","                for i in range(num_segments):\n","                    start = i * SEGMENT_SAMPLES\n","                    end = start + SEGMENT_SAMPLES\n","                    segment = audio[start:end]\n","\n","                    if len(segment) == SEGMENT_SAMPLES:\n","                        data.append(segment)\n","\n","            except Exception as e:\n","                print(f\"\\n‚ö†Ô∏è  Error: {os.path.basename(audio_path)}\")\n","                continue\n","\n","        print(f\"\\n‚úì Processed {len(audio_files)} files\")\n","        print(f\"‚úì Created {len(data)} segments\")\n","\n","        if len(data) > 0:\n","            # Save pickle\n","            pickle_path = os.path.join(PROCESSED_DATA_PATH, 'audio.pkl')\n","            with open(pickle_path, 'wb') as f:\n","                pickle.dump(data, f)\n","\n","            size_mb = os.path.getsize(pickle_path) / (1024 * 1024)\n","\n","            print(f\"\\n‚úì Pickle saved: {pickle_path}\")\n","            print(f\"‚úì Segments: {len(data)}\")\n","            print(f\"‚úì Duration: {len(data)/60:.1f} minutes\")\n","            print(f\"‚úì Size: {size_mb:.1f} MB\")\n","\n","            print(\"\\n\" + \"=\"*50)\n","            print(\"‚úÖ DATA READY FOR TRAINING\")\n","            print(\"=\"*50)\n","\n","            PICKLE_PATH = pickle_path\n","        else:\n","            print(\"‚ùå No segments created\")\n","    else:\n","        print(\"‚ùå No audio files found\")"],"metadata":{"id":"prepare-data","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763289729858,"user_tz":-330,"elapsed":72345,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"eb145e58-9af2-43c6-9e9c-f443374727e9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================================\n","DATA PREPARATION\n","==================================================\n","\n","‚úì Found 2699 audio files\n","‚úì Using 50 files for quick test\n","\n","Processing 50 files...\n","Target: 16kHz, 1-second segments\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:48<00:00,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","‚úì Processed 50 files\n","‚úì Created 396 segments\n","\n","‚úì Pickle saved: /content/processed_data/audio.pkl\n","‚úì Segments: 396\n","‚úì Duration: 6.6 minutes\n","‚úì Size: 24.2 MB\n","\n","==================================================\n","‚úÖ DATA READY FOR TRAINING\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## 4. Training Configuration"],"metadata":{"id":"config-header"}},{"cell_type":"code","source":["# Override batch size in config file\n","import yaml\n","\n","config_path = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/config.yaml'\n","\n","# Read config\n","with open(config_path, 'r') as f:\n","    config = yaml.load(f, Loader=yaml.FullLoader)\n","\n","# Change batch size\n","config['train']['batch_size'] = 1  # Try batch size 2 (very small)\n","config['train']['num_workers'] = 0  # Disable multiprocessing\n","\n","# Save config\n","with open(config_path, 'w') as f:\n","    yaml.dump(config, f)\n","\n","print(f\"‚úì Updated config: batch_size = {config['train']['batch_size']}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PE4oqIQDPZD-","executionInfo":{"status":"ok","timestamp":1763289734124,"user_tz":-330,"elapsed":865,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"38afb293-fa59-45d7-db19-ebbcbab32ab3"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Updated config: batch_size = 1\n"]}]},{"cell_type":"code","source":["# Training hyperparameters\n","BATCH_SIZE = 1\n","NUM_ITERATIONS = 100  # Quick test (use 10000+ for full training)\n","SAVE_EVERY = 40\n","\n","print(\"Training Configuration:\")\n","print(f\"  Batch size: {BATCH_SIZE}\")\n","print(f\"  Iterations: {NUM_ITERATIONS}\")\n","print(f\"  Device: {device}\")\n","print(f\"  Save every: {SAVE_EVERY} iterations\")\n","print(f\"  Pickle path: {PICKLE_PATH}\")"],"metadata":{"id":"training-config","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763289738841,"user_tz":-330,"elapsed":19,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"06efa7fd-26ee-4b79-e4f1-4eaf6243f940"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Configuration:\n","  Batch size: 1\n","  Iterations: 100\n","  Device: cuda\n","  Save every: 40 iterations\n","  Pickle path: /content/processed_data/audio.pkl\n"]}]},{"cell_type":"markdown","source":["## 5. Train Model"],"metadata":{"id":"train-header"}},{"cell_type":"code","source":["# Verify IDEAW files exist\n","import os\n","\n","ideaw_path = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW'\n","\n","print(\"=\"*50)\n","print(\"VERIFYING IDEAW FILES\")\n","print(\"=\"*50)\n","\n","# Check if directory exists\n","if not os.path.exists(ideaw_path):\n","    print(f\"‚ùå IDEAW directory not found: {ideaw_path}\")\n","else:\n","    print(f\"‚úì IDEAW directory exists: {ideaw_path}\")\n","\n","    # List all files in IDEAW\n","    print(\"\\nFiles in IDEAW:\")\n","    for item in os.listdir(ideaw_path):\n","        item_path = os.path.join(ideaw_path, item)\n","        if os.path.isdir(item_path):\n","            print(f\"  üìÅ {item}/\")\n","        else:\n","            print(f\"  üìÑ {item}\")\n","\n","    # Check critical files\n","    critical_files = [\n","        'solver.py',\n","        'config.yaml',\n","        'metrics.py',\n","        'data/dataset.py',\n","        'data/config.yaml',\n","        'models/ideaw.py',\n","        'models/config.yaml'\n","    ]\n","\n","    print(\"\\nCritical files check:\")\n","    all_exist = True\n","    for file in critical_files:\n","        file_path = os.path.join(ideaw_path, file)\n","        if os.path.exists(file_path):\n","            print(f\"  ‚úì {file}\")\n","        else:\n","            print(f\"  ‚ùå {file} - MISSING!\")\n","            all_exist = False\n","\n","    if all_exist:\n","        print(\"\\n‚úÖ All critical files present\")\n","    else:\n","        print(\"\\n‚ùå Some files are missing!\")\n","        print(\"You may need to re-clone the repository\")\n","\n","print(\"=\"*50)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_IEB6M1InDS","executionInfo":{"status":"ok","timestamp":1763289743062,"user_tz":-330,"elapsed":31,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"51f25bf4-bdba-4f47-bdd7-04071a0d737c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================================\n","VERIFYING IDEAW FILES\n","==================================================\n","‚úì IDEAW directory exists: /content/drive/MyDrive/audio-watermarking-demo/research/IDEAW\n","\n","Files in IDEAW:\n","  üìÑ requirements.txt\n","  üìÑ embed_extract.py\n","  üìÑ solver.py\n","  üìÑ LICENSE\n","  üìÑ train.sh\n","  üìÑ train.py\n","  üìÑ README.md\n","  üìÅ models/\n","  üìÅ _DataParallel_version/\n","  üìÑ requirements_colab.txt\n","  üìÅ __pycache__/\n","  üìÅ data/\n","  üìÑ .gitignore\n","  üìÑ metrics.py\n","  üìÑ config.yaml\n","\n","Critical files check:\n","  ‚úì solver.py\n","  ‚úì config.yaml\n","  ‚úì metrics.py\n","  ‚úì data/dataset.py\n","  ‚úì data/config.yaml\n","  ‚úì models/ideaw.py\n","  ‚úì models/config.yaml\n","\n","‚úÖ All critical files present\n","==================================================\n"]}]},{"cell_type":"code","source":["# Initialize solver - use Drive path\n","import sys\n","import os\n","import argparse\n","\n","# Change to IDEAW directory on Drive\n","IDEAW_PATH = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW'\n","os.chdir(IDEAW_PATH)\n","sys.path.insert(0, IDEAW_PATH)\n","\n","print(f\"‚úì Working directory: {os.getcwd()}\")\n","\n","from solver import Solver\n","\n","# Create args object\n","args = argparse.Namespace(\n","    device=device,\n","    pickle_path=PICKLE_PATH,\n","    train_config='./config.yaml',\n","    store_model_path=f'{CHECKPOINT_PATH}/',\n","    load_model=True,  # Changed to True\n","    load_model_path=f'{CHECKPOINT_PATH}/stage_I/',  # Load from stage_I\n","    summary_steps=10,\n","    save_steps=SAVE_EVERY\n",")\n","\n","\n","config_data_path = './data/config.yaml'\n","config_model_path = './models/config.yaml'\n","\n","print(\"Initializing solver...\")\n","solver = Solver(config_data_path, config_model_path, args)\n","\n","print(\"‚úì Solver initialized\")\n","print(\"\\nStarting training...\")\n","print(\"=\"*50)"],"metadata":{"id":"init-solver","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763289779382,"user_tz":-330,"elapsed":32431,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"b087ddd1-c464-4e49-cc0a-d5b550e99148"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Working directory: /content/drive/MyDrive/audio-watermarking-demo/research/IDEAW\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n","  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n","/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n","  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n","/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n","  elif re.match('(flt)p?( \\(default\\))?$', token):\n","/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n","  elif re.match('(dbl)p?( \\(default\\))?$', token):\n"]},{"output_type":"stream","name":"stdout","text":["Initializing solver...\n","[IDEAW]infinite dataloader built\n","[IDEAW]model built\n","[IDEAW]total parameter count: 8425023\n","[IDEAW]optimizers built\n","[IDEAW]load model from /content/drive/MyDrive/audio-watermarking-demo/checkpoints/stage_I/\n","‚úì Solver initialized\n","\n","Starting training...\n","==================================================\n"]}]},{"cell_type":"code","source":["os.makedirs('./output', exist_ok=True)\n","os.makedirs('./tmp', exist_ok=True)\n","\n","print(\"‚úì Created output and tmp directories\")\n","print(\"‚ö†Ô∏è  Restart training from checkpoint\")"],"metadata":{"id":"y7sdiL93wcgt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763289784391,"user_tz":-330,"elapsed":36,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"87799f8e-4278-49d4-c015-35d7b462b226"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Created output and tmp directories\n","‚ö†Ô∏è  Restart training from checkpoint\n"]}]},{"cell_type":"code","source":["# Training loop\n","import time\n","\n","start_time = time.time()\n","\n","try:\n","    solver.train(NUM_ITERATIONS)\n","\n","    training_time = time.time() - start_time\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"‚úÖ TRAINING COMPLETE\")\n","    print(\"=\"*50)\n","    print(f\"Time: {training_time/60:.1f} minutes\")\n","    print(f\"Checkpoints saved to: {CHECKPOINT_PATH}\")\n","\n","except KeyboardInterrupt:\n","    print(\"\\n‚ö†Ô∏è  Training interrupted\")\n","    print(\"Checkpoints saved.\")\n","\n","except Exception as e:\n","    print(f\"\\n‚ùå Error: {e}\")\n","    import traceback\n","    traceback.print_exc()"],"metadata":{"id":"train-loop","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763289984990,"user_tz":-330,"elapsed":166279,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"27f172bc-a47c-4e90-913e-eca505cddb88"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[IDEAW]starting training...\n","[IDEAW]:[10/100] Robustness=False shift=False loss_percept=0.051931 loss_integ=1.005611 loss_discr=1.366115 loss_ident=0.668761 SNR=14.814451 acc_msg=0.586957 acc_lcode=0.700000\n","[IDEAW]:[20/100] Robustness=False shift=False loss_percept=0.088335 loss_integ=0.984366 loss_discr=1.355642 loss_ident=0.659299 SNR=15.807396 acc_msg=0.565217 acc_lcode=0.900000\n","[IDEAW]:[30/100] Robustness=False shift=True loss_percept=0.048516 loss_integ=1.320238 loss_discr=1.359543 loss_ident=0.665926 SNR=5.835968 acc_msg=0.391304 acc_lcode=1.000000\n","[IDEAW]:[40/100] Robustness=False shift=True loss_percept=0.045530 loss_integ=1.383266 loss_discr=1.362298 loss_ident=0.669865 SNR=10.934721 acc_msg=0.413043 acc_lcode=0.600000\n","[IDEAW]:[50/100] Robustness=False shift=True loss_percept=0.063218 loss_integ=1.245444 loss_discr=1.354537 loss_ident=0.660293 SNR=7.740037 acc_msg=0.434783 acc_lcode=0.800000\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/models/attackLayer.py:92: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n","Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n","  k = math.sqrt(p_s / (10 ** (self.snr / 10) * p_n))\n"]},{"output_type":"stream","name":"stdout","text":["[IDEAW]:[60/100] Robustness=True shift=True loss_percept=0.055722 loss_integ=0.998393 loss_discr=1.350756 loss_ident=0.657148 SNR=5.381632 acc_msg=0.565217 acc_lcode=0.900000\n","[IDEAW]:[70/100] Robustness=True shift=True loss_percept=0.069932 loss_integ=1.304842 loss_discr=1.364030 loss_ident=0.676435 SNR=12.123808 acc_msg=0.478261 acc_lcode=0.500000\n","\n","‚ùå Error: [Errno 2] No such file or directory: './tmp/tmp.wav'\n"]},{"output_type":"stream","name":"stderr","text":["Traceback (most recent call last):\n","  File \"/tmp/ipython-input-1121475498.py\", line 7, in <cell line: 0>\n","    solver.train(NUM_ITERATIONS)\n","  File \"/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/solver.py\", line 242, in train\n","    ) = self.model(host_audio, watermark_msg, locate_code, robustness, shift)\n","        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/models/ideaw.py\", line 51, in forward\n","    audio_att = self.attack_layer(audio_wmd2, audio)\n","                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/models/attackLayer.py\", line 69, in forward\n","    att_audio = self.mp3compress(audio)\n","                ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/models/attackLayer.py\", line 177, in forward\n","    wav_segment = pydub.AudioSegment.from_wav(\"./tmp/tmp.wav\")\n","                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pydub/audio_segment.py\", line 808, in from_wav\n","    return cls.from_file(file, 'wav', parameters=parameters)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pydub/audio_segment.py\", line 651, in from_file\n","    file, close_file = _fd_or_path_or_tempfile(file, 'rb', tempfile=False)\n","                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pydub/utils.py\", line 60, in _fd_or_path_or_tempfile\n","    fd = open(fd, mode=mode)\n","         ^^^^^^^^^^^^^^^^^^^\n","FileNotFoundError: [Errno 2] No such file or directory: './tmp/tmp.wav'\n"]}]},{"cell_type":"markdown","source":["## 6. Visualize Training Results"],"metadata":{"id":"viz-header"}},{"cell_type":"code","source":["# Plot training curves\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","log_file = f'{RESULTS_PATH}/training_log.csv'\n","\n","if os.path.exists(log_file):\n","    df = pd.read_csv(log_file)\n","\n","    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n","\n","    # Loss\n","    axes[0, 0].plot(df['epoch'], df['loss'])\n","    axes[0, 0].set_xlabel('Epoch')\n","    axes[0, 0].set_ylabel('Loss')\n","    axes[0, 0].set_title('Training Loss')\n","    axes[0, 0].grid(True)\n","\n","    # SNR\n","    axes[0, 1].plot(df['epoch'], df['snr'])\n","    axes[0, 1].set_xlabel('Epoch')\n","    axes[0, 1].set_ylabel('SNR (dB)')\n","    axes[0, 1].set_title('Signal-to-Noise Ratio')\n","    axes[0, 1].grid(True)\n","\n","    # Accuracy\n","    axes[1, 0].plot(df['epoch'], df['accuracy'])\n","    axes[1, 0].set_xlabel('Epoch')\n","    axes[1, 0].set_ylabel('Accuracy (%)')\n","    axes[1, 0].set_title('Watermark Accuracy')\n","    axes[1, 0].grid(True)\n","\n","    # Learning rate\n","    if 'learning_rate' in df.columns:\n","        axes[1, 1].plot(df['epoch'], df['learning_rate'])\n","        axes[1, 1].set_xlabel('Epoch')\n","        axes[1, 1].set_ylabel('Learning Rate')\n","        axes[1, 1].set_title('Learning Rate Schedule')\n","        axes[1, 1].set_yscale('log')\n","        axes[1, 1].grid(True)\n","\n","    plt.tight_layout()\n","    plt.savefig(f'{RESULTS_PATH}/training_curves.png', dpi=300, bbox_inches='tight')\n","    plt.show()\n","\n","    print(\"‚úì Training curves saved to:\", f'{RESULTS_PATH}/training_curves.png')\n","\n","    # Print final metrics\n","    print(\"\\nFinal Metrics:\")\n","    print(f\"  Loss: {df['loss'].iloc[-1]:.4f}\")\n","    print(f\"  SNR: {df['snr'].iloc[-1]:.2f} dB\")\n","    print(f\"  Accuracy: {df['accuracy'].iloc[-1]:.2f}%\")\n","else:\n","    print(\"‚ö†Ô∏è No training log found\")"],"metadata":{"id":"visualize"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 7. Test Trained Model"],"metadata":{"id":"test-header"}},{"cell_type":"code","source":["# Load best checkpoint\n","best_checkpoint = f'{CHECKPOINT_PATH}/best_model.pth'\n","\n","if os.path.exists(best_checkpoint):\n","    print(\"Loading best model...\")\n","    checkpoint = torch.load(best_checkpoint)\n","    ideaw.load_state_dict(checkpoint['model_state_dict'])\n","    ideaw.eval()\n","    print(\"‚úì Best model loaded\")\n","\n","    # Test on sample audio\n","    import librosa\n","    import numpy as np\n","\n","    # Load test audio\n","    test_audio_path = f'{LOCAL_DATA_PATH}/val/test_audio.wav'  # Update with your test file\n","\n","    if os.path.exists(test_audio_path):\n","        audio, sr = librosa.load(test_audio_path, sr=16000)\n","        audio_tensor = torch.FloatTensor(audio).unsqueeze(0).to(device)\n","\n","        # Generate random message and location code\n","        message = torch.randint(0, 2, (1, 16), dtype=torch.float32).to(device)\n","        lcode = torch.randint(0, 2, (1, 10), dtype=torch.float32).to(device)\n","\n","        with torch.no_grad():\n","            # Embed\n","            audio_wmd1, _ = ideaw.embed_msg(audio_tensor, message)\n","            audio_wmd2, _ = ideaw.embed_lcode(audio_wmd1, lcode)\n","\n","            # Extract\n","            mid_stft, lcode_extracted = ideaw.extract_lcode(audio_wmd2)\n","            message_extracted = ideaw.extract_msg(mid_stft)\n","\n","            # Calculate accuracy\n","            msg_acc = ((message_extracted > 0.5).float() == message).float().mean().item() * 100\n","            lcode_acc = ((lcode_extracted > 0.5).float() == lcode).float().mean().item() * 100\n","\n","            print(f\"\\nTest Results:\")\n","            print(f\"  Message accuracy: {msg_acc:.2f}%\")\n","            print(f\"  Location code accuracy: {lcode_acc:.2f}%\")\n","    else:\n","        print(f\"‚ö†Ô∏è Test audio not found at {test_audio_path}\")\n","else:\n","    print(f\"‚ö†Ô∏è Checkpoint not found at {best_checkpoint}\")"],"metadata":{"id":"test-model"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 8. Download Results"],"metadata":{"id":"download-header"}},{"cell_type":"code","source":["# Zip checkpoints and results\n","!zip -r checkpoints.zip {CHECKPOINT_PATH}\n","!zip -r results.zip {RESULTS_PATH}\n","\n","print(\"‚úì Files zipped\")\n","print(\"\\nYou can download:\")\n","print(\"  1. checkpoints.zip - Trained model weights\")\n","print(\"  2. results.zip - Training logs and plots\")\n","print(\"\\nOr access them directly from Google Drive at:\")\n","print(f\"  {DRIVE_PATH}\")"],"metadata":{"id":"download"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optional: Download directly from Colab\n","from google.colab import files\n","\n","# Uncomment to download\n","# files.download('checkpoints.zip')\n","# files.download('results.zip')"],"metadata":{"id":"download-direct"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 9. Push Code Updates to GitHub (Optional)"],"metadata":{"id":"push-github-header"}},{"cell_type":"code","source":["# If you made code changes in Colab, push them back to GitHub\n","\n","# Configure git (first time only)\n","!git config --global user.email \"your.email@example.com\"\n","!git config --global user.name \"Your Name\"\n","\n","# Check what changed\n","!git status\n","\n","# Add, commit, and push (uncomment to use)\n","# !git add .\n","# !git commit -m \"Updated training code from Colab\"\n","# !git push\n","\n","print(\"\\nNote: You'll need to authenticate with GitHub token if pushing\")\n","print(\"Generate token at: https://github.com/settings/tokens\")"],"metadata":{"id":"push-github"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10. Pull Latest Code Updates (Optional)"],"metadata":{"id":"pull-github-header"}},{"cell_type":"code","source":["# If you updated code on your local machine, pull latest changes\n","!git pull origin main\n","\n","print(\"‚úì Code updated from GitHub\")"],"metadata":{"id":"pull-github"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 11. Keep Session Alive (Optional)\n","\n","Run this JavaScript in your browser console to prevent disconnection:\n","\n","```javascript\n","function KeepAlive() {\n","    console.log(\"Keeping session alive...\");\n","    document.querySelector(\"colab-connect-button\").click();\n","}\n","setInterval(KeepAlive, 60000);\n","```"],"metadata":{"id":"keep-alive"}}]}