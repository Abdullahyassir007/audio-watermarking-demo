{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# IDEAW Training on Google Colab\n","\n","This notebook trains IDEAW audio watermarking models using Colab's free GPU.\n","\n","**Before running:**\n","1. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n","2. Upload your data to Google Drive\n","3. Update the GitHub URL below with your repository"],"metadata":{"id":"header"}},{"cell_type":"markdown","source":["## 1. Setup Environment"],"metadata":{"id":"setup-header"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","%cd /content/drive/MyDrive/audio-watermarking-demo\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoRH8Wi3rz44","executionInfo":{"status":"ok","timestamp":1763235698661,"user_tz":-330,"elapsed":1872,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"1a149b4d-76ca-4c74-eafa-a73db2f9bfbf"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/audio-watermarking-demo\n"]}]},{"cell_type":"code","source":["!git status\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGjpwQ2sx8fm","executionInfo":{"status":"ok","timestamp":1763235087208,"user_tz":-330,"elapsed":930,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"d54f8f5c-2da4-4ac5-9b7f-c053f59c1c38"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   colab_notebooks/IDEAW_Training_Template.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","source":["!git reset --soft HEAD~5\n"],"metadata":{"id":"ilKL3OpaznrZ","executionInfo":{"status":"ok","timestamp":1763233735517,"user_tz":-330,"elapsed":184,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["!git add colab_notebooks/IDEAW_Training_Template.ipynb\n","\n","# 4. Commit with a message\n","!git commit -m \"Created training structure\"\n","\n","# 5. Push to GitHub\n","!git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UTP6ZO0mzgnz","executionInfo":{"status":"ok","timestamp":1763237956614,"user_tz":-330,"elapsed":1485,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"7492f48d-e6fe-4519-8352-edf7a7c11f51"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["warning: could not open directory 'research/IDEAW/colab_notebooks/': No such file or directory\n","fatal: pathspec 'colab_notebooks/IDEAW_Training_Template.ipynb' did not match any files\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   ../../colab_notebooks/IDEAW_Training_Template.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n","To https://github.com/AbdullahYassir007/audio-watermarking-demo.git\n"," \u001b[31m! [rejected]       \u001b[m main -> main (fetch first)\n","\u001b[31merror: failed to push some refs to 'https://github.com/AbdullahYassir007/audio-watermarking-demo.git'\n","\u001b[m\u001b[33mhint: Updates were rejected because the remote contains work that you do\u001b[m\n","\u001b[33mhint: not have locally. This is usually caused by another repository pushing\u001b[m\n","\u001b[33mhint: to the same ref. You may want to first integrate the remote changes\u001b[m\n","\u001b[33mhint: (e.g., 'git pull ...') before pushing again.\u001b[m\n","\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n"]}]},{"cell_type":"code","source":["# !git checkout -- colab_notebooks/IDEAW_Training_Template.ipynb\n","!git pull origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wRxHZDvYsN8J","executionInfo":{"status":"ok","timestamp":1763233792766,"user_tz":-330,"elapsed":592,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"9b927dc0-365d-418e-edce-fe4c3050323f"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["From https://github.com/AbdullahYassir007/audio-watermarking-demo\n"," * branch            main       -> FETCH_HEAD\n","Already up to date.\n"]}]},{"cell_type":"code","source":["\n","\n","# Set up paths\n","DRIVE_PATH = '/content/drive/MyDrive/audio-watermarking-demo'\n","DATA_PATH = f'{DRIVE_PATH}/Dataset'\n","CHECKPOINT_PATH = f'{DRIVE_PATH}/checkpoints'\n","RESULTS_PATH = f'{DRIVE_PATH}/results'\n","\n","# Create directories\n","import os\n","os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n","os.makedirs(RESULTS_PATH, exist_ok=True)\n","\n","print(\"‚úì Google Drive mounted\")\n","print(f\"‚úì Data path: {DATA_PATH}\")\n","print(f\"‚úì Checkpoint path: {CHECKPOINT_PATH}\")\n","print(f\"‚úì Results path: {RESULTS_PATH}\")"],"metadata":{"id":"mount-drive","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763235701418,"user_tz":-330,"elapsed":34,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"33524064-8ed4-498e-9dbf-eb53c0f8e15e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Google Drive mounted\n","‚úì Data path: /content/drive/MyDrive/audio-watermarking-demo/Dataset\n","‚úì Checkpoint path: /content/drive/MyDrive/audio-watermarking-demo/checkpoints\n","‚úì Results path: /content/drive/MyDrive/audio-watermarking-demo/results\n"]}]},{"cell_type":"code","source":["# Install dependencies from IDEAW requirements\n","!pip install -q -r research/IDEAW/requirements_colab.txt\n","!pip install -q FrEIA\n","\n","print(\"‚úì Dependencies installed\")"],"metadata":{"id":"install-deps","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763235715163,"user_tz":-330,"elapsed":9380,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"e1b505f6-3866-46c4-affc-024ed0fdcea3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Dependencies installed\n"]}]},{"cell_type":"code","source":["# Check GPU availability\n","import torch\n","\n","print(f\"GPU Available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n","    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","    device = 'cuda'\n","else:\n","    print(\"‚ö†Ô∏è No GPU available, using CPU\")\n","    device = 'cpu'\n","\n","print(f\"\\n‚úì Using device: {device}\")"],"metadata":{"id":"check-gpu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763235715191,"user_tz":-330,"elapsed":25,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"81c1d9f0-e958-4246-bf94-9ef072481e33"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Available: True\n","GPU Name: Tesla T4\n","GPU Memory: 15.83 GB\n","\n","‚úì Using device: cuda\n"]}]},{"cell_type":"code","source":["# Just install the missing packages, use Colab's existing PyTorch\n","!pip install -q librosa==0.10.1 pydub PyYAML soundfile tqdm resampy\n","\n","# Restart runtime\n","import os\n","os.kill(os.getpid(), 9)\n","\n"],"metadata":{"id":"1KKuaYkDBVnw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Verify installation\n","import torch\n","import librosa\n","import scipy\n","import numpy as np\n","import yaml\n","\n","print(\"=\" * 50)\n","print(\"ENVIRONMENT CHECK\")\n","print(\"=\" * 50)\n","print(f\"‚úì PyTorch: {torch.__version__}\")\n","print(f\"‚úì Librosa: {librosa.__version__}\")\n","print(f\"‚úì Scipy: {scipy.__version__}\")\n","print(f\"‚úì Numpy: {np.__version__}\")\n","print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n","print(\"=\" * 50)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0527lnznCL1i","executionInfo":{"status":"ok","timestamp":1763235720393,"user_tz":-330,"elapsed":16,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"5c11f35a-2ae4-401c-dd37-117b4c6e6a69"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================================\n","ENVIRONMENT CHECK\n","==================================================\n","‚úì PyTorch: 2.8.0+cu126\n","‚úì Librosa: 0.10.1\n","‚úì Scipy: 1.11.4\n","‚úì Numpy: 1.26.4\n","‚úì CUDA available: True\n","‚úì GPU: Tesla T4\n","==================================================\n"]}]},{"cell_type":"markdown","source":["## 2. Load IDEAW Model"],"metadata":{"id":"load-model-header"}},{"cell_type":"code","source":["# Import IDEAW\n","import sys\n","sys.path.insert(0, '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW')\n","\n","from models.ideaw import IDEAW\n","\n","# Configuration\n","config_path = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/config.yaml'\n","model_config_path = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/models/config.yaml'\n","\n","# Initialize model\n","ideaw = IDEAW(model_config_path, device)\n","print(\"‚úì IDEAW model initialized\")\n","\n","# Count parameters\n","total_params = sum(p.numel() for p in ideaw.parameters())\n","trainable_params = sum(p.numel() for p in ideaw.parameters() if p.requires_grad)\n","print(f\"Total parameters: {total_params:,}\")\n","print(f\"Trainable parameters: {trainable_params:,}\")"],"metadata":{"id":"load-model","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763235730460,"user_tz":-330,"elapsed":818,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"b4d6fe7d-2c16-49c8-aea1-510efaa96892"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì IDEAW model initialized\n","Total parameters: 8,425,023\n","Trainable parameters: 8,425,023\n"]}]},{"cell_type":"markdown","source":["## 3. Prepare Data"],"metadata":{"id":"data-header"}},{"cell_type":"code","source":["# ============================================\n","# PREPARE DATA FOR IDEAW TRAINING\n","# ============================================\n","import os\n","import pickle\n","import librosa\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Paths\n","DRIVE_PATH = '/content/drive/MyDrive/audio-watermarking-demo'\n","RAW_DATA_PATH = f'{DRIVE_PATH}/Dataset'\n","PROCESSED_DATA_PATH = '/content/processed_data'\n","CHECKPOINT_PATH = f'{DRIVE_PATH}/checkpoints'\n","RESULTS_PATH = f'{DRIVE_PATH}/results'\n","\n","# Parameters\n","MAX_FILES = 50  # Quick test with 50 files (set to None for all)\n","SAMPLE_RATE = 16000\n","SEGMENT_SAMPLES = 16000  # 1 second\n","\n","# Create directories\n","os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n","os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n","os.makedirs(f'{CHECKPOINT_PATH}/stage_I', exist_ok=True)\n","os.makedirs(f'{CHECKPOINT_PATH}/stage_II', exist_ok=True)\n","os.makedirs(RESULTS_PATH, exist_ok=True)\n","\n","print(\"=\"*50)\n","print(\"DATA PREPARATION\")\n","print(\"=\"*50)\n","\n","# Find audio files\n","if not os.path.exists(RAW_DATA_PATH):\n","    print(f\"‚ùå Data not found at {RAW_DATA_PATH}\")\n","else:\n","    audio_extensions = ['.mp3', '.wav', '.flac', '.m4a']\n","    audio_files = []\n","\n","    for root, dirs, files in os.walk(RAW_DATA_PATH):\n","        for file in files:\n","            if any(file.lower().endswith(ext) for ext in audio_extensions):\n","                audio_files.append(os.path.join(root, file))\n","\n","    print(f\"\\n‚úì Found {len(audio_files)} audio files\")\n","\n","    # Limit for testing\n","    if MAX_FILES and len(audio_files) > MAX_FILES:\n","        audio_files = audio_files[:MAX_FILES]\n","        print(f\"‚úì Using {MAX_FILES} files for quick test\")\n","\n","    if len(audio_files) > 0:\n","        print(f\"\\nProcessing {len(audio_files)} files...\")\n","        print(f\"Target: 16kHz, 1-second segments\")\n","\n","        data = []\n","\n","        for audio_path in tqdm(audio_files):\n","            try:\n","                # Load and resample\n","                audio, sr = librosa.load(audio_path, sr=SAMPLE_RATE, mono=True)\n","\n","                # Split into 1-second segments\n","                num_segments = int(len(audio) / SEGMENT_SAMPLES)\n","\n","                for i in range(num_segments):\n","                    start = i * SEGMENT_SAMPLES\n","                    end = start + SEGMENT_SAMPLES\n","                    segment = audio[start:end]\n","\n","                    if len(segment) == SEGMENT_SAMPLES:\n","                        data.append(segment)\n","\n","            except Exception as e:\n","                print(f\"\\n‚ö†Ô∏è  Error: {os.path.basename(audio_path)}\")\n","                continue\n","\n","        print(f\"\\n‚úì Processed {len(audio_files)} files\")\n","        print(f\"‚úì Created {len(data)} segments\")\n","\n","        if len(data) > 0:\n","            # Save pickle\n","            pickle_path = os.path.join(PROCESSED_DATA_PATH, 'audio.pkl')\n","            with open(pickle_path, 'wb') as f:\n","                pickle.dump(data, f)\n","\n","            size_mb = os.path.getsize(pickle_path) / (1024 * 1024)\n","\n","            print(f\"\\n‚úì Pickle saved: {pickle_path}\")\n","            print(f\"‚úì Segments: {len(data)}\")\n","            print(f\"‚úì Duration: {len(data)/60:.1f} minutes\")\n","            print(f\"‚úì Size: {size_mb:.1f} MB\")\n","\n","            print(\"\\n\" + \"=\"*50)\n","            print(\"‚úÖ DATA READY FOR TRAINING\")\n","            print(\"=\"*50)\n","\n","            PICKLE_PATH = pickle_path\n","        else:\n","            print(\"‚ùå No segments created\")\n","    else:\n","        print(\"‚ùå No audio files found\")"],"metadata":{"id":"prepare-data","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763236906985,"user_tz":-330,"elapsed":12001,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"f2214311-4efa-4f71-b67c-3d7289d02644"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================================\n","DATA PREPARATION\n","==================================================\n","\n","‚úì Found 2707 audio files\n","‚úì Using 50 files for quick test\n","\n","Processing 50 files...\n","Target: 16kHz, 1-second segments\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:11<00:00,  4.23it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","‚úì Processed 50 files\n","‚úì Created 532 segments\n","\n","‚úì Pickle saved: /content/processed_data/audio.pkl\n","‚úì Segments: 532\n","‚úì Duration: 8.9 minutes\n","‚úì Size: 32.5 MB\n","\n","==================================================\n","‚úÖ DATA READY FOR TRAINING\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## 4. Training Configuration"],"metadata":{"id":"config-header"}},{"cell_type":"code","source":["# Training hyperparameters\n","BATCH_SIZE = 16\n","NUM_ITERATIONS = 1000  # Quick test (use 10000+ for full training)\n","SAVE_EVERY = 100\n","\n","print(\"Training Configuration:\")\n","print(f\"  Batch size: {BATCH_SIZE}\")\n","print(f\"  Iterations: {NUM_ITERATIONS}\")\n","print(f\"  Device: {device}\")\n","print(f\"  Save every: {SAVE_EVERY} iterations\")\n","print(f\"  Pickle path: {PICKLE_PATH}\")"],"metadata":{"id":"training-config","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763237112070,"user_tz":-330,"elapsed":23,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"dcdd6719-4426-4600-83ad-939b3b891e19"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Configuration:\n","  Batch size: 16\n","  Iterations: 1000\n","  Device: cuda\n","  Save every: 100 iterations\n","  Pickle path: /content/processed_data/audio.pkl\n"]}]},{"cell_type":"markdown","source":["## 5. Train Model"],"metadata":{"id":"train-header"}},{"cell_type":"code","source":["# Verify IDEAW files exist\n","import os\n","\n","ideaw_path = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW'\n","\n","print(\"=\"*50)\n","print(\"VERIFYING IDEAW FILES\")\n","print(\"=\"*50)\n","\n","# Check if directory exists\n","if not os.path.exists(ideaw_path):\n","    print(f\"‚ùå IDEAW directory not found: {ideaw_path}\")\n","else:\n","    print(f\"‚úì IDEAW directory exists: {ideaw_path}\")\n","\n","    # List all files in IDEAW\n","    print(\"\\nFiles in IDEAW:\")\n","    for item in os.listdir(ideaw_path):\n","        item_path = os.path.join(ideaw_path, item)\n","        if os.path.isdir(item_path):\n","            print(f\"  üìÅ {item}/\")\n","        else:\n","            print(f\"  üìÑ {item}\")\n","\n","    # Check critical files\n","    critical_files = [\n","        'solver.py',\n","        'config.yaml',\n","        'metrics.py',\n","        'data/dataset.py',\n","        'data/config.yaml',\n","        'models/ideaw.py',\n","        'models/config.yaml'\n","    ]\n","\n","    print(\"\\nCritical files check:\")\n","    all_exist = True\n","    for file in critical_files:\n","        file_path = os.path.join(ideaw_path, file)\n","        if os.path.exists(file_path):\n","            print(f\"  ‚úì {file}\")\n","        else:\n","            print(f\"  ‚ùå {file} - MISSING!\")\n","            all_exist = False\n","\n","    if all_exist:\n","        print(\"\\n‚úÖ All critical files present\")\n","    else:\n","        print(\"\\n‚ùå Some files are missing!\")\n","        print(\"You may need to re-clone the repository\")\n","\n","print(\"=\"*50)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_IEB6M1InDS","executionInfo":{"status":"ok","timestamp":1763237651367,"user_tz":-330,"elapsed":10,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"be947768-df0a-4f35-97c8-f1283324e7ee"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================================\n","VERIFYING IDEAW FILES\n","==================================================\n","‚úì IDEAW directory exists: /content/drive/MyDrive/audio-watermarking-demo/research/IDEAW\n","\n","Files in IDEAW:\n","  üìÑ .gitignore\n","  üìÑ LICENSE\n","  üìÑ README.md\n","  üìÅ _DataParallel_version/\n","  üìÑ config.yaml\n","  üìÑ embed_extract.py\n","  üìÑ metrics.py\n","  üìÅ models/\n","  üìÑ requirements.txt\n","  üìÑ solver.py\n","  üìÑ train.py\n","  üìÑ train.sh\n","  üìÑ requirements_colab.txt\n","  üìÅ __pycache__/\n","\n","Critical files check:\n","  ‚úì solver.py\n","  ‚úì config.yaml\n","  ‚úì metrics.py\n","  ‚ùå data/dataset.py - MISSING!\n","  ‚ùå data/config.yaml - MISSING!\n","  ‚úì models/ideaw.py\n","  ‚úì models/config.yaml\n","\n","‚ùå Some files are missing!\n","You may need to re-clone the repository\n","==================================================\n"]}]},{"cell_type":"code","source":["# Initialize solver - use Drive path\n","import sys\n","import os\n","import argparse\n","\n","# Change to IDEAW directory on Drive\n","IDEAW_PATH = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW'\n","os.chdir(IDEAW_PATH)\n","sys.path.insert(0, IDEAW_PATH)\n","\n","print(f\"‚úì Working directory: {os.getcwd()}\")\n","\n","from solver import Solver\n","\n","# Create args object\n","args = argparse.Namespace(\n","    device=device,\n","    pickle_path=PICKLE_PATH,\n","    train_config='./config.yaml',\n","    store_model_path=f'{CHECKPOINT_PATH}/',\n","    load_model=False,\n","    load_model_path=None,\n","    summary_steps=10,\n","    save_steps=SAVE_EVERY\n",")\n","\n","config_data_path = './data/config.yaml'\n","config_model_path = './models/config.yaml'\n","\n","print(\"Initializing solver...\")\n","solver = Solver(config_data_path, config_model_path, args)\n","\n","print(\"‚úì Solver initialized\")\n","print(\"\\nStarting training...\")\n","print(\"=\"*50)"],"metadata":{"id":"init-solver","colab":{"base_uri":"https://localhost:8080/","height":546},"executionInfo":{"status":"error","timestamp":1763237656052,"user_tz":-330,"elapsed":59,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"09e917eb-ee3e-45df-a03f-4c9181633700"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Working directory: /content/drive/MyDrive/audio-watermarking-demo/research/IDEAW\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'data'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3744117034.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚úì Working directory: {os.getcwd()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Create args object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/solver.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAWdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfinite_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mideaw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIDEAW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalc_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_noise_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["# Training loop\n","import time\n","from tqdm import tqdm\n","\n","start_time = time.time()\n","\n","try:\n","    solver.train(\n","        save_path=CHECKPOINT_PATH,\n","        log_path=RESULTS_PATH,\n","        num_epochs=NUM_EPOCHS,\n","        save_every=SAVE_EVERY\n","    )\n","\n","    training_time = time.time() - start_time\n","    print(\"\\n\" + \"=\" * 50)\n","    print(\"‚úì Training completed!\")\n","    print(f\"Total training time: {training_time / 3600:.2f} hours\")\n","\n","except KeyboardInterrupt:\n","    print(\"\\n‚ö†Ô∏è Training interrupted by user\")\n","    print(\"Checkpoints have been saved.\")\n","\n","except Exception as e:\n","    print(f\"\\n‚ùå Training error: {e}\")\n","    import traceback\n","    traceback.print_exc()"],"metadata":{"id":"train-loop"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Visualize Training Results"],"metadata":{"id":"viz-header"}},{"cell_type":"code","source":["# Plot training curves\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","log_file = f'{RESULTS_PATH}/training_log.csv'\n","\n","if os.path.exists(log_file):\n","    df = pd.read_csv(log_file)\n","\n","    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n","\n","    # Loss\n","    axes[0, 0].plot(df['epoch'], df['loss'])\n","    axes[0, 0].set_xlabel('Epoch')\n","    axes[0, 0].set_ylabel('Loss')\n","    axes[0, 0].set_title('Training Loss')\n","    axes[0, 0].grid(True)\n","\n","    # SNR\n","    axes[0, 1].plot(df['epoch'], df['snr'])\n","    axes[0, 1].set_xlabel('Epoch')\n","    axes[0, 1].set_ylabel('SNR (dB)')\n","    axes[0, 1].set_title('Signal-to-Noise Ratio')\n","    axes[0, 1].grid(True)\n","\n","    # Accuracy\n","    axes[1, 0].plot(df['epoch'], df['accuracy'])\n","    axes[1, 0].set_xlabel('Epoch')\n","    axes[1, 0].set_ylabel('Accuracy (%)')\n","    axes[1, 0].set_title('Watermark Accuracy')\n","    axes[1, 0].grid(True)\n","\n","    # Learning rate\n","    if 'learning_rate' in df.columns:\n","        axes[1, 1].plot(df['epoch'], df['learning_rate'])\n","        axes[1, 1].set_xlabel('Epoch')\n","        axes[1, 1].set_ylabel('Learning Rate')\n","        axes[1, 1].set_title('Learning Rate Schedule')\n","        axes[1, 1].set_yscale('log')\n","        axes[1, 1].grid(True)\n","\n","    plt.tight_layout()\n","    plt.savefig(f'{RESULTS_PATH}/training_curves.png', dpi=300, bbox_inches='tight')\n","    plt.show()\n","\n","    print(\"‚úì Training curves saved to:\", f'{RESULTS_PATH}/training_curves.png')\n","\n","    # Print final metrics\n","    print(\"\\nFinal Metrics:\")\n","    print(f\"  Loss: {df['loss'].iloc[-1]:.4f}\")\n","    print(f\"  SNR: {df['snr'].iloc[-1]:.2f} dB\")\n","    print(f\"  Accuracy: {df['accuracy'].iloc[-1]:.2f}%\")\n","else:\n","    print(\"‚ö†Ô∏è No training log found\")"],"metadata":{"id":"visualize"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 7. Test Trained Model"],"metadata":{"id":"test-header"}},{"cell_type":"code","source":["# Load best checkpoint\n","best_checkpoint = f'{CHECKPOINT_PATH}/best_model.pth'\n","\n","if os.path.exists(best_checkpoint):\n","    print(\"Loading best model...\")\n","    checkpoint = torch.load(best_checkpoint)\n","    ideaw.load_state_dict(checkpoint['model_state_dict'])\n","    ideaw.eval()\n","    print(\"‚úì Best model loaded\")\n","\n","    # Test on sample audio\n","    import librosa\n","    import numpy as np\n","\n","    # Load test audio\n","    test_audio_path = f'{LOCAL_DATA_PATH}/val/test_audio.wav'  # Update with your test file\n","\n","    if os.path.exists(test_audio_path):\n","        audio, sr = librosa.load(test_audio_path, sr=16000)\n","        audio_tensor = torch.FloatTensor(audio).unsqueeze(0).to(device)\n","\n","        # Generate random message and location code\n","        message = torch.randint(0, 2, (1, 16), dtype=torch.float32).to(device)\n","        lcode = torch.randint(0, 2, (1, 10), dtype=torch.float32).to(device)\n","\n","        with torch.no_grad():\n","            # Embed\n","            audio_wmd1, _ = ideaw.embed_msg(audio_tensor, message)\n","            audio_wmd2, _ = ideaw.embed_lcode(audio_wmd1, lcode)\n","\n","            # Extract\n","            mid_stft, lcode_extracted = ideaw.extract_lcode(audio_wmd2)\n","            message_extracted = ideaw.extract_msg(mid_stft)\n","\n","            # Calculate accuracy\n","            msg_acc = ((message_extracted > 0.5).float() == message).float().mean().item() * 100\n","            lcode_acc = ((lcode_extracted > 0.5).float() == lcode).float().mean().item() * 100\n","\n","            print(f\"\\nTest Results:\")\n","            print(f\"  Message accuracy: {msg_acc:.2f}%\")\n","            print(f\"  Location code accuracy: {lcode_acc:.2f}%\")\n","    else:\n","        print(f\"‚ö†Ô∏è Test audio not found at {test_audio_path}\")\n","else:\n","    print(f\"‚ö†Ô∏è Checkpoint not found at {best_checkpoint}\")"],"metadata":{"id":"test-model"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 8. Download Results"],"metadata":{"id":"download-header"}},{"cell_type":"code","source":["# Zip checkpoints and results\n","!zip -r checkpoints.zip {CHECKPOINT_PATH}\n","!zip -r results.zip {RESULTS_PATH}\n","\n","print(\"‚úì Files zipped\")\n","print(\"\\nYou can download:\")\n","print(\"  1. checkpoints.zip - Trained model weights\")\n","print(\"  2. results.zip - Training logs and plots\")\n","print(\"\\nOr access them directly from Google Drive at:\")\n","print(f\"  {DRIVE_PATH}\")"],"metadata":{"id":"download"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optional: Download directly from Colab\n","from google.colab import files\n","\n","# Uncomment to download\n","# files.download('checkpoints.zip')\n","# files.download('results.zip')"],"metadata":{"id":"download-direct"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 9. Push Code Updates to GitHub (Optional)"],"metadata":{"id":"push-github-header"}},{"cell_type":"code","source":["# If you made code changes in Colab, push them back to GitHub\n","\n","# Configure git (first time only)\n","!git config --global user.email \"your.email@example.com\"\n","!git config --global user.name \"Your Name\"\n","\n","# Check what changed\n","!git status\n","\n","# Add, commit, and push (uncomment to use)\n","# !git add .\n","# !git commit -m \"Updated training code from Colab\"\n","# !git push\n","\n","print(\"\\nNote: You'll need to authenticate with GitHub token if pushing\")\n","print(\"Generate token at: https://github.com/settings/tokens\")"],"metadata":{"id":"push-github"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10. Pull Latest Code Updates (Optional)"],"metadata":{"id":"pull-github-header"}},{"cell_type":"code","source":["# If you updated code on your local machine, pull latest changes\n","!git pull origin main\n","\n","print(\"‚úì Code updated from GitHub\")"],"metadata":{"id":"pull-github"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 11. Keep Session Alive (Optional)\n","\n","Run this JavaScript in your browser console to prevent disconnection:\n","\n","```javascript\n","function KeepAlive() {\n","    console.log(\"Keeping session alive...\");\n","    document.querySelector(\"colab-connect-button\").click();\n","}\n","setInterval(KeepAlive, 60000);\n","```"],"metadata":{"id":"keep-alive"}}]}