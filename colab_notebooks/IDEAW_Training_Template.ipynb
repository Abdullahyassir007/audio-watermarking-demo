{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# IDEAW Training on Google Colab\n","\n","This notebook trains IDEAW audio watermarking models using Colab's free GPU.\n","\n","**Before running:**\n","1. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n","2. Upload your data to Google Drive\n","3. Update the GitHub URL below with your repository"],"metadata":{"id":"header"}},{"cell_type":"markdown","source":["## 1. Setup Environment"],"metadata":{"id":"setup-header"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","%cd /content/drive/MyDrive/audio-watermarking-demo\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoRH8Wi3rz44","executionInfo":{"status":"ok","timestamp":1763291327311,"user_tz":-330,"elapsed":2330,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"49a5429b-5aac-4da8-a275-8c2da03626a6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/audio-watermarking-demo\n"]}]},{"cell_type":"code","source":["!git status\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGjpwQ2sx8fm","executionInfo":{"status":"ok","timestamp":1763290188117,"user_tz":-330,"elapsed":33977,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"581ff155-f49d-45ef-9ba9-b3ddae0a30dc"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["^C\n"]}]},{"cell_type":"code","source":["!git reset --soft HEAD~5\n"],"metadata":{"id":"ilKL3OpaznrZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add colab_notebooks/IDEAW_Training_Template.ipynb"],"metadata":{"id":"nrGMoGE9SF0B","executionInfo":{"status":"ok","timestamp":1763290471782,"user_tz":-330,"elapsed":1135,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["!git config --global user.name \"Abdullah Yassir\"\n","!git config --global user.email \"abdullahyassir2222@gmail.com\"\n"],"metadata":{"id":"WdmuoYP8V4yG","executionInfo":{"status":"ok","timestamp":1763291171812,"user_tz":-330,"elapsed":203,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"directories added\"\n","\n","!git push origin main\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WpD__ypaSYsg","executionInfo":{"status":"ok","timestamp":1763291175284,"user_tz":-330,"elapsed":1594,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"e2196169-cdb9-4263-a6df-8b0e6d1be6c1"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   colab_notebooks/IDEAW_Training_Template.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n","Everything up-to-date\n"]}]},{"cell_type":"code","metadata":{"id":"30ac6263","executionInfo":{"status":"ok","timestamp":1763290615601,"user_tz":-330,"elapsed":114,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}}},"source":["# List all untracked files recursively, excluding those ignored by .gitignore\n","!git ls-files --others --exclude-standard"],"execution_count":28,"outputs":[]},{"cell_type":"code","source":["!git add colab_notebooks/IDEAW_Training_Template.ipynb\n","\n","# 4. Commit with a message\n","!git commit -m \"Running training loop\"\n","\n","# 5. Push to GitHub\n","!git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UTP6ZO0mzgnz","executionInfo":{"status":"ok","timestamp":1763241774930,"user_tz":-330,"elapsed":3674,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"d30e447d-2ca0-43c2-dbe7-9cfc94a9e12b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 486d4a1] Running training loop\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite colab_notebooks/IDEAW_Training_Template.ipynb (97%)\n","Enumerating objects: 7, done.\n","Counting objects: 100% (7/7), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (4/4), done.\n","Writing objects: 100% (4/4), 5.23 KiB | 382.00 KiB/s, done.\n","Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","remote: This repository moved. Please use the new location:\u001b[K\n","remote:   https://github.com/Abdullahyassir007/audio-watermarking-demo.git\u001b[K\n","To https://github.com/AbdullahYassir007/audio-watermarking-demo.git\n","   8dccca0..486d4a1  main -> main\n"]}]},{"cell_type":"code","source":["# !git checkout -- colab_notebooks/IDEAW_Training_Template.ipynb\n","!git pull origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wRxHZDvYsN8J","executionInfo":{"status":"ok","timestamp":1763292321605,"user_tz":-330,"elapsed":1085,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"5d93ee3e-d447-4038-8f68-3d62c42ce93c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["From https://github.com/Abdullahyassir007/audio-watermarking-demo\n"," * branch            main       -> FETCH_HEAD\n","Already up to date.\n"]}]},{"cell_type":"code","source":["# Abort the rebase\n","!git rebase --abort\n","\n","# Accept the remote version (my fix)\n","!git reset --hard origin/main\n","\n","# Now re-apply just your notebook and config changes\n","!git checkout HEAD~1 -- colab_notebooks/IDEAW_Training_Template.ipynb\n","!git checkout HEAD~1 -- research/IDEAW/config.yaml\n","\n","# Commit these changes\n","!git add colab_notebooks/IDEAW_Training_Template.ipynb research/IDEAW/config.yaml\n","!git commit -m \"Update Colab notebook and config for batch size 2\"\n","\n","# Push\n","!git push origin main\n"],"metadata":{"id":"XMgPpj37RhRd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763239781619,"user_tz":-330,"elapsed":3853,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"a96d8e8a-9396-4872-c8d3-599b113faf11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["HEAD is now at e0e1c82 Fix IDEAW PyTorch 2.x compatibility - STFT/iSTFT complex tensor handling\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n","Everything up-to-date\n"]}]},{"cell_type":"code","source":["\n","\n","# Set up paths\n","DRIVE_PATH = '/content/drive/MyDrive/audio-watermarking-demo'\n","DATA_PATH = f'{DRIVE_PATH}/Dataset'\n","CHECKPOINT_PATH = f'{DRIVE_PATH}/checkpoints'\n","RESULTS_PATH = f'{DRIVE_PATH}/results'\n","\n","# Create directories\n","import os\n","os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n","os.makedirs(RESULTS_PATH, exist_ok=True)\n","\n","print(\"‚úì Google Drive mounted\")\n","print(f\"‚úì Data path: {DATA_PATH}\")\n","print(f\"‚úì Checkpoint path: {CHECKPOINT_PATH}\")\n","print(f\"‚úì Results path: {RESULTS_PATH}\")"],"metadata":{"id":"mount-drive","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763291379341,"user_tz":-330,"elapsed":77,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"e2a1f78f-ba8c-4132-99f4-03a0f4afa221"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Google Drive mounted\n","‚úì Data path: /content/drive/MyDrive/audio-watermarking-demo/Dataset\n","‚úì Checkpoint path: /content/drive/MyDrive/audio-watermarking-demo/checkpoints\n","‚úì Results path: /content/drive/MyDrive/audio-watermarking-demo/results\n"]}]},{"cell_type":"code","source":["# # Just install the missing packages, use Colab's existing PyTorch\n","# !pip install -q librosa==0.10.1 pydub PyYAML soundfile tqdm resampy\n","\n","# # Restart runtime\n","# import os\n","# os.kill(os.getpid(), 9)\n","\n"],"metadata":{"id":"1KKuaYkDBVnw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Install dependencies from IDEAW requirements\n","# !pip install -q -r research/IDEAW/requirements_colab.txt\n","# !pip install -q FrEIA\n","\n","# print(\"‚úì Dependencies installed\")"],"metadata":{"id":"install-deps","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763289624554,"user_tz":-330,"elapsed":8886,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"56cc7927-62ac-414b-bc23-f9c51fa2d151"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Dependencies installed\n"]}]},{"cell_type":"code","source":["# Check GPU availability\n","import torch\n","\n","print(f\"GPU Available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n","    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","    device = 'cuda'\n","else:\n","    print(\"‚ö†Ô∏è No GPU available, using CPU\")\n","    device = 'cpu'\n","\n","print(f\"\\n‚úì Using device: {device}\")"],"metadata":{"id":"check-gpu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763291383199,"user_tz":-330,"elapsed":1982,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"bec50fee-f843-4250-97b8-3792f728c519"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Available: True\n","GPU Name: Tesla T4\n","GPU Memory: 15.83 GB\n","\n","‚úì Using device: cuda\n"]}]},{"cell_type":"code","source":["# Verify installation\n","import torch\n","import librosa\n","import scipy\n","import numpy as np\n","import yaml\n","\n","print(\"=\" * 50)\n","print(\"ENVIRONMENT CHECK\")\n","print(\"=\" * 50)\n","print(f\"‚úì PyTorch: {torch.__version__}\")\n","print(f\"‚úì Librosa: {librosa.__version__}\")\n","print(f\"‚úì Scipy: {scipy.__version__}\")\n","print(f\"‚úì Numpy: {np.__version__}\")\n","print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n","print(\"=\" * 50)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0527lnznCL1i","executionInfo":{"status":"ok","timestamp":1763291384483,"user_tz":-330,"elapsed":38,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"20c700bd-761b-401c-c5aa-a4ab143d4566"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================================\n","ENVIRONMENT CHECK\n","==================================================\n","‚úì PyTorch: 2.8.0+cu126\n","‚úì Librosa: 0.10.1\n","‚úì Scipy: 1.11.4\n","‚úì Numpy: 1.26.4\n","‚úì CUDA available: True\n","‚úì GPU: Tesla T4\n","==================================================\n"]}]},{"cell_type":"markdown","source":["## 2. Load IDEAW Model"],"metadata":{"id":"load-model-header"}},{"cell_type":"code","source":["# # Import IDEAW\n","# import sys\n","# sys.path.insert(0, '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW')\n","\n","# from models.ideaw import IDEAW\n","\n","# # Configuration\n","# config_path = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/config.yaml'\n","# model_config_path = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/models/config.yaml'\n","\n","# # Initialize model\n","# ideaw = IDEAW(model_config_path, device)\n","# print(\"‚úì IDEAW model initialized\")\n","\n","# # Count parameters\n","# total_params = sum(p.numel() for p in ideaw.parameters())\n","# trainable_params = sum(p.numel() for p in ideaw.parameters() if p.requires_grad)\n","# print(f\"Total parameters: {total_params:,}\")\n","# print(f\"Trainable parameters: {trainable_params:,}\")"],"metadata":{"id":"load-model","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763238758256,"user_tz":-330,"elapsed":1715,"user":{"displayName":"Abdullah Yassir","userId":"02050531084960743622"}},"outputId":"9251dcd3-152d-483f-ad20-084007e25279"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì IDEAW model initialized\n","Total parameters: 8,425,023\n","Trainable parameters: 8,425,023\n"]}]},{"cell_type":"markdown","source":["## 3. Prepare Data"],"metadata":{"id":"data-header"}},{"cell_type":"code","source":["# ============================================\n","# PREPARE DATA FOR IDEAW TRAINING\n","# ============================================\n","import os\n","import pickle\n","import librosa\n","import numpy as np\n","from tqdm import tqdm\n","\n","# Paths\n","DRIVE_PATH = '/content/drive/MyDrive/audio-watermarking-demo'\n","RAW_DATA_PATH = f'{DRIVE_PATH}/Dataset'\n","PROCESSED_DATA_PATH = '/content/processed_data'\n","CHECKPOINT_PATH = f'{DRIVE_PATH}/checkpoints'\n","RESULTS_PATH = f'{DRIVE_PATH}/results'\n","\n","# Parameters\n","MAX_FILES = 50  # Quick test with 50 files (set to None for all)\n","SAMPLE_RATE = 16000\n","SEGMENT_SAMPLES = 16000  # 1 second\n","\n","# Create directories\n","os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n","os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n","os.makedirs(f'{CHECKPOINT_PATH}/stage_I', exist_ok=True)\n","os.makedirs(f'{CHECKPOINT_PATH}/stage_II', exist_ok=True)\n","os.makedirs(RESULTS_PATH, exist_ok=True)\n","\n","print(\"=\"*50)\n","print(\"DATA PREPARATION\")\n","print(\"=\"*50)\n","\n","# Find audio files\n","if not os.path.exists(RAW_DATA_PATH):\n","    print(f\"‚ùå Data not found at {RAW_DATA_PATH}\")\n","else:\n","    audio_extensions = ['.mp3', '.wav', '.flac', '.m4a']\n","    audio_files = []\n","\n","    for root, dirs, files in os.walk(RAW_DATA_PATH):\n","        for file in files:\n","            if any(file.lower().endswith(ext) for ext in audio_extensions):\n","                audio_files.append(os.path.join(root, file))\n","\n","    print(f\"\\n‚úì Found {len(audio_files)} audio files\")\n","\n","    # Limit for testing\n","    if MAX_FILES and len(audio_files) > MAX_FILES:\n","        audio_files = audio_files[:MAX_FILES]\n","        print(f\"‚úì Using {MAX_FILES} files for quick test\")\n","\n","    if len(audio_files) > 0:\n","        print(f\"\\nProcessing {len(audio_files)} files...\")\n","        print(f\"Target: 16kHz, 1-second segments\")\n","\n","        data = []\n","\n","        for audio_path in tqdm(audio_files):\n","            try:\n","                # Load and resample\n","                audio, sr = librosa.load(audio_path, sr=SAMPLE_RATE, mono=True)\n","\n","                # Split into 1-second segments\n","                num_segments = int(len(audio) / SEGMENT_SAMPLES)\n","\n","                for i in range(num_segments):\n","                    start = i * SEGMENT_SAMPLES\n","                    end = start + SEGMENT_SAMPLES\n","                    segment = audio[start:end]\n","\n","                    if len(segment) == SEGMENT_SAMPLES:\n","                        data.append(segment)\n","\n","            except Exception as e:\n","                print(f\"\\n‚ö†Ô∏è  Error: {os.path.basename(audio_path)}\")\n","                continue\n","\n","        print(f\"\\n‚úì Processed {len(audio_files)} files\")\n","        print(f\"‚úì Created {len(data)} segments\")\n","\n","        if len(data) > 0:\n","            # Save pickle\n","            pickle_path = os.path.join(PROCESSED_DATA_PATH, 'audio.pkl')\n","            with open(pickle_path, 'wb') as f:\n","                pickle.dump(data, f)\n","\n","            size_mb = os.path.getsize(pickle_path) / (1024 * 1024)\n","\n","            print(f\"\\n‚úì Pickle saved: {pickle_path}\")\n","            print(f\"‚úì Segments: {len(data)}\")\n","            print(f\"‚úì Duration: {len(data)/60:.1f} minutes\")\n","            print(f\"‚úì Size: {size_mb:.1f} MB\")\n","\n","            print(\"\\n\" + \"=\"*50)\n","            print(\"‚úÖ DATA READY FOR TRAINING\")\n","            print(\"=\"*50)\n","\n","            PICKLE_PATH = pickle_path\n","        else:\n","            print(\"‚ùå No segments created\")\n","    else:\n","        print(\"‚ùå No audio files found\")"],"metadata":{"id":"prepare-data","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763291392236,"user_tz":-330,"elapsed":3361,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"2f5fe7f0-dff2-47f9-9927-f53a58104688"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================================\n","DATA PREPARATION\n","==================================================\n","\n","‚úì Found 2699 audio files\n","‚úì Using 50 files for quick test\n","\n","Processing 50 files...\n","Target: 16kHz, 1-second segments\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:03<00:00, 16.60it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","‚úì Processed 50 files\n","‚úì Created 396 segments\n","\n","‚úì Pickle saved: /content/processed_data/audio.pkl\n","‚úì Segments: 396\n","‚úì Duration: 6.6 minutes\n","‚úì Size: 24.2 MB\n","\n","==================================================\n","‚úÖ DATA READY FOR TRAINING\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## 4. Training Configuration"],"metadata":{"id":"config-header"}},{"cell_type":"code","source":["# Override batch size in config file\n","import yaml\n","\n","config_path = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/config.yaml'\n","\n","# Read config\n","with open(config_path, 'r') as f:\n","    config = yaml.load(f, Loader=yaml.FullLoader)\n","\n","# Change batch size\n","config['train']['batch_size'] = 1  # Try batch size 2 (very small)\n","config['train']['num_workers'] = 0  # Disable multiprocessing\n","\n","# Save config\n","with open(config_path, 'w') as f:\n","    yaml.dump(config, f)\n","\n","print(f\"‚úì Updated config: batch_size = {config['train']['batch_size']}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PE4oqIQDPZD-","executionInfo":{"status":"ok","timestamp":1763291394348,"user_tz":-330,"elapsed":47,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"f9f68702-025f-44f1-ba71-c620f2d7e11b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Updated config: batch_size = 1\n"]}]},{"cell_type":"code","source":["# Training hyperparameters\n","BATCH_SIZE = 1\n","NUM_ITERATIONS = 100  # Quick test (use 10000+ for full training)\n","SAVE_EVERY = 40\n","\n","print(\"Training Configuration:\")\n","print(f\"  Batch size: {BATCH_SIZE}\")\n","print(f\"  Iterations: {NUM_ITERATIONS}\")\n","print(f\"  Device: {device}\")\n","print(f\"  Save every: {SAVE_EVERY} iterations\")\n","print(f\"  Pickle path: {PICKLE_PATH}\")"],"metadata":{"id":"training-config","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763291397356,"user_tz":-330,"elapsed":43,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"af5da318-9b02-4d53-dd41-ababff1f99f8"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Configuration:\n","  Batch size: 1\n","  Iterations: 100\n","  Device: cuda\n","  Save every: 40 iterations\n","  Pickle path: /content/processed_data/audio.pkl\n"]}]},{"cell_type":"markdown","source":["## 5. Train Model"],"metadata":{"id":"train-header"}},{"cell_type":"code","source":["# Verify IDEAW files exist\n","import os\n","\n","ideaw_path = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW'\n","\n","print(\"=\"*50)\n","print(\"VERIFYING IDEAW FILES\")\n","print(\"=\"*50)\n","\n","# Check if directory exists\n","if not os.path.exists(ideaw_path):\n","    print(f\"‚ùå IDEAW directory not found: {ideaw_path}\")\n","else:\n","    print(f\"‚úì IDEAW directory exists: {ideaw_path}\")\n","\n","    # List all files in IDEAW\n","    print(\"\\nFiles in IDEAW:\")\n","    for item in os.listdir(ideaw_path):\n","        item_path = os.path.join(ideaw_path, item)\n","        if os.path.isdir(item_path):\n","            print(f\"  üìÅ {item}/\")\n","        else:\n","            print(f\"  üìÑ {item}\")\n","\n","    # Check critical files\n","    critical_files = [\n","        'solver.py',\n","        'config.yaml',\n","        'metrics.py',\n","        'data/dataset.py',\n","        'data/config.yaml',\n","        'models/ideaw.py',\n","        'models/config.yaml'\n","    ]\n","\n","    print(\"\\nCritical files check:\")\n","    all_exist = True\n","    for file in critical_files:\n","        file_path = os.path.join(ideaw_path, file)\n","        if os.path.exists(file_path):\n","            print(f\"  ‚úì {file}\")\n","        else:\n","            print(f\"  ‚ùå {file} - MISSING!\")\n","            all_exist = False\n","\n","    if all_exist:\n","        print(\"\\n‚úÖ All critical files present\")\n","    else:\n","        print(\"\\n‚ùå Some files are missing!\")\n","        print(\"You may need to re-clone the repository\")\n","\n","print(\"=\"*50)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_IEB6M1InDS","executionInfo":{"status":"ok","timestamp":1763291399996,"user_tz":-330,"elapsed":46,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"5c67ddf6-7f61-4414-b3fe-1f8aa4515db6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================================\n","VERIFYING IDEAW FILES\n","==================================================\n","‚úì IDEAW directory exists: /content/drive/MyDrive/audio-watermarking-demo/research/IDEAW\n","\n","Files in IDEAW:\n","  üìÑ requirements.txt\n","  üìÑ embed_extract.py\n","  üìÑ solver.py\n","  üìÑ LICENSE\n","  üìÑ train.sh\n","  üìÑ train.py\n","  üìÑ README.md\n","  üìÅ models/\n","  üìÅ _DataParallel_version/\n","  üìÑ requirements_colab.txt\n","  üìÅ __pycache__/\n","  üìÅ data/\n","  üìÑ .gitignore\n","  üìÑ metrics.py\n","  üìÑ config.yaml\n","  üìÅ output/\n","  üìÅ tmp/\n","\n","Critical files check:\n","  ‚úì solver.py\n","  ‚úì config.yaml\n","  ‚úì metrics.py\n","  ‚úì data/dataset.py\n","  ‚úì data/config.yaml\n","  ‚úì models/ideaw.py\n","  ‚úì models/config.yaml\n","\n","‚úÖ All critical files present\n","==================================================\n"]}]},{"cell_type":"code","source":["# Initialize solver - use Drive path\n","import sys\n","import os\n","import argparse\n","\n","# Change to IDEAW directory on Drive\n","IDEAW_PATH = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW'\n","os.chdir(IDEAW_PATH)\n","sys.path.insert(0, IDEAW_PATH)\n","\n","print(f\"‚úì Working directory: {os.getcwd()}\")\n","\n","from solver import Solver\n","\n","# Create args object\n","args = argparse.Namespace(\n","    device=device,\n","    pickle_path=PICKLE_PATH,\n","    train_config='./config.yaml',\n","    store_model_path=f'{CHECKPOINT_PATH}/',\n","    load_model=True,  # Changed to True\n","    load_model_path=f'{CHECKPOINT_PATH}/stage_I/',  # Load from stage_I\n","    summary_steps=10,\n","    save_steps=SAVE_EVERY\n",")\n","\n","\n","config_data_path = './data/config.yaml'\n","config_model_path = './models/config.yaml'\n","\n","print(\"Initializing solver...\")\n","solver = Solver(config_data_path, config_model_path, args)\n","\n","print(\"‚úì Solver initialized\")\n","print(\"\\nStarting training...\")\n","print(\"=\"*50)"],"metadata":{"id":"init-solver","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763291405954,"user_tz":-330,"elapsed":2514,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"2b7f7493-b4e1-4534-e340-4eeb5fec18c5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Working directory: /content/drive/MyDrive/audio-watermarking-demo/research/IDEAW\n","Initializing solver...\n","[IDEAW]infinite dataloader built\n","[IDEAW]model built\n","[IDEAW]total parameter count: 8425023\n","[IDEAW]optimizers built\n","[IDEAW]load model from /content/drive/MyDrive/audio-watermarking-demo/checkpoints/stage_I/\n","‚úì Solver initialized\n","\n","Starting training...\n","==================================================\n"]}]},{"cell_type":"code","source":["os.makedirs('./output', exist_ok=True)\n","os.makedirs('./tmp', exist_ok=True)\n","\n","print(\"‚úì Created output and tmp directories\")\n","print(\"‚ö†Ô∏è  Restart training from checkpoint\")"],"metadata":{"id":"y7sdiL93wcgt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763289784391,"user_tz":-330,"elapsed":36,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"87799f8e-4278-49d4-c015-35d7b462b226"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Created output and tmp directories\n","‚ö†Ô∏è  Restart training from checkpoint\n"]}]},{"cell_type":"code","source":["# Training loop\n","import time\n","\n","start_time = time.time()\n","\n","try:\n","    solver.train(NUM_ITERATIONS)\n","\n","    training_time = time.time() - start_time\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"‚úÖ TRAINING COMPLETE\")\n","    print(\"=\"*50)\n","    print(f\"Time: {training_time/60:.1f} minutes\")\n","    print(f\"Checkpoints saved to: {CHECKPOINT_PATH}\")\n","\n","except KeyboardInterrupt:\n","    print(\"\\n‚ö†Ô∏è  Training interrupted\")\n","    print(\"Checkpoints saved.\")\n","\n","except Exception as e:\n","    print(f\"\\n‚ùå Error: {e}\")\n","    import traceback\n","    traceback.print_exc()"],"metadata":{"id":"train-loop","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763291640696,"user_tz":-330,"elapsed":230420,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"44d5d78b-22f7-40da-e28b-44a2e20da99b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[IDEAW]starting training...\n","[IDEAW]:[10/100] Robustness=False shift=False loss_percept=0.063857 loss_integ=1.115202 loss_discr=1.350542 loss_ident=0.657412 SNR=-3.619636 acc_msg=0.521739 acc_lcode=0.800000\n","[IDEAW]:[20/100] Robustness=False shift=False loss_percept=0.048959 loss_integ=1.177563 loss_discr=1.358223 loss_ident=0.664613 SNR=3.226653 acc_msg=0.478261 acc_lcode=0.900000\n","[IDEAW]:[30/100] Robustness=False shift=True loss_percept=0.031871 loss_integ=1.132025 loss_discr=1.365473 loss_ident=0.671432 SNR=8.031628 acc_msg=0.521739 acc_lcode=0.700000\n","[IDEAW]:[40/100] Robustness=False shift=True loss_percept=0.075020 loss_integ=1.176194 loss_discr=1.360777 loss_ident=0.656165 SNR=15.951397 acc_msg=0.500000 acc_lcode=0.800000\n","[IDEAW]:[50/100] Robustness=False shift=True loss_percept=0.075395 loss_integ=1.190669 loss_discr=1.346068 loss_ident=0.654293 SNR=0.570390 acc_msg=0.478261 acc_lcode=0.700000\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/models/attackLayer.py:92: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n","Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n","  k = math.sqrt(p_s / (10 ** (self.snr / 10) * p_n))\n"]},{"output_type":"stream","name":"stdout","text":["[IDEAW]:[60/100] Robustness=True shift=True loss_percept=0.047829 loss_integ=1.377067 loss_discr=1.357157 loss_ident=0.662954 SNR=10.746403 acc_msg=0.434783 acc_lcode=0.500000\n","[IDEAW]:[70/100] Robustness=True shift=True loss_percept=0.041373 loss_integ=1.007230 loss_discr=1.358699 loss_ident=0.664071 SNR=14.993973 acc_msg=0.543478 acc_lcode=1.000000\n","[IDEAW]:[80/100] Robustness=True shift=True loss_percept=0.045261 loss_integ=1.164460 loss_discr=1.353836 loss_ident=0.659120 SNR=11.130965 acc_msg=0.478261 acc_lcode=0.800000\n","[IDEAW]:[90/100] Robustness=True shift=True loss_percept=0.029037 loss_integ=1.274569 loss_discr=1.371923 loss_ident=0.679292 SNR=14.167888 acc_msg=0.413043 acc_lcode=0.900000\n","[IDEAW]:[100/100] Robustness=True shift=True loss_percept=0.045201 loss_integ=1.151209 loss_discr=1.355892 loss_ident=0.662642 SNR=5.919544 acc_msg=0.478261 acc_lcode=1.000000\n","\n","==================================================\n","‚úÖ TRAINING COMPLETE\n","==================================================\n","Time: 3.8 minutes\n","Checkpoints saved to: /content/drive/MyDrive/audio-watermarking-demo/checkpoints\n"]}]},{"cell_type":"code","source":["# Simpler test - just check if checkpoint loads and model structure is correct\n","import sys\n","import os\n","import torch\n","\n","sys.path.insert(0, '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW')\n","\n","from models.ideaw import IDEAW\n","\n","# Initialize model\n","model_config_path = '/content/drive/MyDrive/audio-watermarking-demo/research/IDEAW/models/config.yaml'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","ideaw = IDEAW(model_config_path, device)\n","ideaw = ideaw.to(device)\n","print(\"‚úì IDEAW model initialized\")\n","\n","# Load checkpoint\n","checkpoint_path = '/content/drive/MyDrive/audio-watermarking-demo/checkpoints/stage_I/ideaw.ckpt'\n","\n","if os.path.exists(checkpoint_path):\n","    print(f\"Loading checkpoint from: {checkpoint_path}\")\n","    checkpoint = torch.load(checkpoint_path)\n","    ideaw.load_state_dict(checkpoint)\n","    ideaw.eval()\n","    print(\"‚úì Checkpoint loaded successfully\")\n","\n","    # Count parameters\n","    total_params = sum(p.numel() for p in ideaw.parameters())\n","    print(f\"‚úì Model parameters: {total_params:,}\")\n","\n","    print(\"\\n‚úÖ CHECKPOINT TEST PASSED!\")\n","    print(\"The model checkpoint is valid and can be loaded.\")\n","    print(\"\\nTo properly test watermarking:\")\n","    print(\"1. Use the standalone_demo.py script\")\n","    print(\"2. Or continue training to improve accuracy\")\n","\n","else:\n","    print(f\"‚ùå Checkpoint not found at {checkpoint_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gHVAu8oMYcp-","executionInfo":{"status":"ok","timestamp":1763291977373,"user_tz":-330,"elapsed":667,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"0c441e8e-4023-4ccd-9461-ff0a864c51d5"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì IDEAW model initialized\n","Loading checkpoint from: /content/drive/MyDrive/audio-watermarking-demo/checkpoints/stage_I/ideaw.ckpt\n","‚úì Checkpoint loaded successfully\n","‚úì Model parameters: 8,425,023\n","\n","‚úÖ CHECKPOINT TEST PASSED!\n","The model checkpoint is valid and can be loaded.\n","\n","To properly test watermarking:\n","1. Use the standalone_demo.py script\n","2. Or continue training to improve accuracy\n"]}]},{"cell_type":"markdown","source":["## 6. Visualize Training Results"],"metadata":{"id":"viz-header"}},{"cell_type":"code","source":["# Plot training curves\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","log_file = f'{RESULTS_PATH}/training_log.csv'\n","\n","if os.path.exists(log_file):\n","    df = pd.read_csv(log_file)\n","\n","    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n","\n","    # Loss\n","    axes[0, 0].plot(df['epoch'], df['loss'])\n","    axes[0, 0].set_xlabel('Epoch')\n","    axes[0, 0].set_ylabel('Loss')\n","    axes[0, 0].set_title('Training Loss')\n","    axes[0, 0].grid(True)\n","\n","    # SNR\n","    axes[0, 1].plot(df['epoch'], df['snr'])\n","    axes[0, 1].set_xlabel('Epoch')\n","    axes[0, 1].set_ylabel('SNR (dB)')\n","    axes[0, 1].set_title('Signal-to-Noise Ratio')\n","    axes[0, 1].grid(True)\n","\n","    # Accuracy\n","    axes[1, 0].plot(df['epoch'], df['accuracy'])\n","    axes[1, 0].set_xlabel('Epoch')\n","    axes[1, 0].set_ylabel('Accuracy (%)')\n","    axes[1, 0].set_title('Watermark Accuracy')\n","    axes[1, 0].grid(True)\n","\n","    # Learning rate\n","    if 'learning_rate' in df.columns:\n","        axes[1, 1].plot(df['epoch'], df['learning_rate'])\n","        axes[1, 1].set_xlabel('Epoch')\n","        axes[1, 1].set_ylabel('Learning Rate')\n","        axes[1, 1].set_title('Learning Rate Schedule')\n","        axes[1, 1].set_yscale('log')\n","        axes[1, 1].grid(True)\n","\n","    plt.tight_layout()\n","    plt.savefig(f'{RESULTS_PATH}/training_curves.png', dpi=300, bbox_inches='tight')\n","    plt.show()\n","\n","    print(\"‚úì Training curves saved to:\", f'{RESULTS_PATH}/training_curves.png')\n","\n","    # Print final metrics\n","    print(\"\\nFinal Metrics:\")\n","    print(f\"  Loss: {df['loss'].iloc[-1]:.4f}\")\n","    print(f\"  SNR: {df['snr'].iloc[-1]:.2f} dB\")\n","    print(f\"  Accuracy: {df['accuracy'].iloc[-1]:.2f}%\")\n","else:\n","    print(\"‚ö†Ô∏è No training log found\")"],"metadata":{"id":"visualize","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763291709210,"user_tz":-330,"elapsed":44,"user":{"displayName":"Abdullah yassir","userId":"06014537306864003482"}},"outputId":"7252d794-0acf-49f4-96d1-5c184a6e6957"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["‚ö†Ô∏è No training log found\n"]}]},{"cell_type":"markdown","source":["## 7. Test Trained Model"],"metadata":{"id":"test-header"}},{"cell_type":"code","source":["# Load best checkpoint\n","best_checkpoint = f'{CHECKPOINT_PATH}/best_model.pth'\n","\n","if os.path.exists(best_checkpoint):\n","    print(\"Loading best model...\")\n","    checkpoint = torch.load(best_checkpoint)\n","    ideaw.load_state_dict(checkpoint['model_state_dict'])\n","    ideaw.eval()\n","    print(\"‚úì Best model loaded\")\n","\n","    # Test on sample audio\n","    import librosa\n","    import numpy as np\n","\n","    # Load test audio\n","    test_audio_path = f'{LOCAL_DATA_PATH}/val/test_audio.wav'  # Update with your test file\n","\n","    if os.path.exists(test_audio_path):\n","        audio, sr = librosa.load(test_audio_path, sr=16000)\n","        audio_tensor = torch.FloatTensor(audio).unsqueeze(0).to(device)\n","\n","        # Generate random message and location code\n","        message = torch.randint(0, 2, (1, 16), dtype=torch.float32).to(device)\n","        lcode = torch.randint(0, 2, (1, 10), dtype=torch.float32).to(device)\n","\n","        with torch.no_grad():\n","            # Embed\n","            audio_wmd1, _ = ideaw.embed_msg(audio_tensor, message)\n","            audio_wmd2, _ = ideaw.embed_lcode(audio_wmd1, lcode)\n","\n","            # Extract\n","            mid_stft, lcode_extracted = ideaw.extract_lcode(audio_wmd2)\n","            message_extracted = ideaw.extract_msg(mid_stft)\n","\n","            # Calculate accuracy\n","            msg_acc = ((message_extracted > 0.5).float() == message).float().mean().item() * 100\n","            lcode_acc = ((lcode_extracted > 0.5).float() == lcode).float().mean().item() * 100\n","\n","            print(f\"\\nTest Results:\")\n","            print(f\"  Message accuracy: {msg_acc:.2f}%\")\n","            print(f\"  Location code accuracy: {lcode_acc:.2f}%\")\n","    else:\n","        print(f\"‚ö†Ô∏è Test audio not found at {test_audio_path}\")\n","else:\n","    print(f\"‚ö†Ô∏è Checkpoint not found at {best_checkpoint}\")"],"metadata":{"id":"test-model"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 8. Download Results"],"metadata":{"id":"download-header"}},{"cell_type":"code","source":["# Zip checkpoints and results\n","!zip -r checkpoints.zip {CHECKPOINT_PATH}\n","!zip -r results.zip {RESULTS_PATH}\n","\n","print(\"‚úì Files zipped\")\n","print(\"\\nYou can download:\")\n","print(\"  1. checkpoints.zip - Trained model weights\")\n","print(\"  2. results.zip - Training logs and plots\")\n","print(\"\\nOr access them directly from Google Drive at:\")\n","print(f\"  {DRIVE_PATH}\")"],"metadata":{"id":"download"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optional: Download directly from Colab\n","from google.colab import files\n","\n","# Uncomment to download\n","# files.download('checkpoints.zip')\n","# files.download('results.zip')"],"metadata":{"id":"download-direct"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 9. Push Code Updates to GitHub (Optional)"],"metadata":{"id":"push-github-header"}},{"cell_type":"code","source":["# If you made code changes in Colab, push them back to GitHub\n","\n","# Configure git (first time only)\n","!git config --global user.email \"your.email@example.com\"\n","!git config --global user.name \"Your Name\"\n","\n","# Check what changed\n","!git status\n","\n","# Add, commit, and push (uncomment to use)\n","# !git add .\n","# !git commit -m \"Updated training code from Colab\"\n","# !git push\n","\n","print(\"\\nNote: You'll need to authenticate with GitHub token if pushing\")\n","print(\"Generate token at: https://github.com/settings/tokens\")"],"metadata":{"id":"push-github"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10. Pull Latest Code Updates (Optional)"],"metadata":{"id":"pull-github-header"}},{"cell_type":"code","source":["# If you updated code on your local machine, pull latest changes\n","!git pull origin main\n","\n","print(\"‚úì Code updated from GitHub\")"],"metadata":{"id":"pull-github"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 11. Keep Session Alive (Optional)\n","\n","Run this JavaScript in your browser console to prevent disconnection:\n","\n","```javascript\n","function KeepAlive() {\n","    console.log(\"Keeping session alive...\");\n","    document.querySelector(\"colab-connect-button\").click();\n","}\n","setInterval(KeepAlive, 60000);\n","```"],"metadata":{"id":"keep-alive"}}]}