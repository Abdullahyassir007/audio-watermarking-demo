{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IDEAW Training on Google Colab\n",
        "\n",
        "This notebook trains IDEAW audio watermarking models using Colab's free GPU.\n",
        "\n",
        "**Before running:**\n",
        "1. Enable GPU: Runtime → Change runtime type → GPU\n",
        "2. Upload your data to Google Drive\n",
        "3. Update the GitHub URL below with your repository"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup Environment"
      ],
      "metadata": {
        "id": "setup-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up paths\n",
        "DRIVE_PATH = '/content/drive/MyDrive/IDEAW_Research'\n",
        "DATA_PATH = f'{DRIVE_PATH}/data'\n",
        "CHECKPOINT_PATH = f'{DRIVE_PATH}/checkpoints'\n",
        "RESULTS_PATH = f'{DRIVE_PATH}/results'\n",
        "\n",
        "# Create directories\n",
        "import os\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
        "\n",
        "print(\"✓ Google Drive mounted\")\n",
        "print(f\"✓ Data path: {DATA_PATH}\")\n",
        "print(f\"✓ Checkpoint path: {CHECKPOINT_PATH}\")\n",
        "print(f\"✓ Results path: {RESULTS_PATH}\")"
      ],
      "metadata": {
        "id": "mount-drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone your repository\n",
        "GITHUB_URL = \"https://github.com/Abdullahyassir007/audio-watermarking-demo.git\"\n",
        "\n",
        "# Remove existing directory if present\n",
        "!rm -rf audio-watermarking-demo\n",
        "\n",
        "# Clone\n",
        "!git clone {GITHUB_URL}\n",
        "%cd audio-watermarking-demo\n",
        "\n",
        "print(\"✓ Repository cloned\")\n",
        "print(f\"✓ Working directory: {!pwd}\")"
      ],
      "metadata": {
        "id": "clone-repo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies from IDEAW requirements\n",
        "!pip install -q -r research/IDEAW/requirements.txt\n",
        "!pip install -q FrEIA\n",
        "\n",
        "print(\"✓ Dependencies installed\")"
      ],
      "metadata": {
        "id": "install-deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"⚠️ No GPU available, using CPU\")\n",
        "    device = 'cpu'\n",
        "\n",
        "print(f\"\\n✓ Using device: {device}\")"
      ],
      "metadata": {
        "id": "check-gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load IDEAW Model"
      ],
      "metadata": {
        "id": "load-model-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import IDEAW\n",
        "import sys\n",
        "sys.path.insert(0, '/content/audio-watermarking-demo/research/IDEAW')\n",
        "\n",
        "from models.ideaw import IDEAW\n",
        "\n",
        "# Configuration\n",
        "config_path = '/content/audio-watermarking-demo/research/IDEAW/config.yaml'\n",
        "model_config_path = '/content/audio-watermarking-demo/research/IDEAW/models/config.yaml'\n",
        "\n",
        "# Initialize model\n",
        "ideaw = IDEAW(model_config_path, device)\n",
        "print(\"✓ IDEAW model initialized\")\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in ideaw.parameters())\n",
        "trainable_params = sum(p.numel() for p in ideaw.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")"
      ],
      "metadata": {
        "id": "load-model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Prepare Data"
      ],
      "metadata": {
        "id": "data-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy data from Drive to local storage (faster training)\n",
        "import shutil\n",
        "\n",
        "LOCAL_DATA_PATH = '/content/data'\n",
        "\n",
        "if os.path.exists(DATA_PATH):\n",
        "    print(\"Copying data from Drive to local storage...\")\n",
        "    if os.path.exists(LOCAL_DATA_PATH):\n",
        "        shutil.rmtree(LOCAL_DATA_PATH)\n",
        "    shutil.copytree(DATA_PATH, LOCAL_DATA_PATH)\n",
        "    print(f\"✓ Data copied to {LOCAL_DATA_PATH}\")\n",
        "    \n",
        "    # Count files\n",
        "    train_files = len(os.listdir(f'{LOCAL_DATA_PATH}/train')) if os.path.exists(f'{LOCAL_DATA_PATH}/train') else 0\n",
        "    val_files = len(os.listdir(f'{LOCAL_DATA_PATH}/val')) if os.path.exists(f'{LOCAL_DATA_PATH}/val') else 0\n",
        "    print(f\"Training files: {train_files}\")\n",
        "    print(f\"Validation files: {val_files}\")\n",
        "else:\n",
        "    print(f\"⚠️ Data not found at {DATA_PATH}\")\n",
        "    print(\"Please upload your training data to Google Drive first.\")"
      ],
      "metadata": {
        "id": "prepare-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training Configuration"
      ],
      "metadata": {
        "id": "config-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 100\n",
        "LEARNING_RATE = 1e-5\n",
        "SAVE_EVERY = 10  # Save checkpoint every N epochs\n",
        "\n",
        "print(\"Training Configuration:\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"  Device: {device}\")\n",
        "print(f\"  Save frequency: Every {SAVE_EVERY} epochs\")"
      ],
      "metadata": {
        "id": "training-config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Train Model"
      ],
      "metadata": {
        "id": "train-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize solver\n",
        "solver = Solver(\n",
        "    config_path=config_path,\n",
        "    model=ideaw,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"✓ Solver initialized\")\n",
        "print(\"\\nStarting training...\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "id": "init-solver"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    solver.train(\n",
        "        save_path=CHECKPOINT_PATH,\n",
        "        log_path=RESULTS_PATH,\n",
        "        num_epochs=NUM_EPOCHS,\n",
        "        save_every=SAVE_EVERY\n",
        "    )\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"✓ Training completed!\")\n",
        "    print(f\"Total training time: {training_time / 3600:.2f} hours\")\n",
        "    \n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n⚠️ Training interrupted by user\")\n",
        "    print(\"Checkpoints have been saved.\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Training error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "train-loop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize Training Results"
      ],
      "metadata": {
        "id": "viz-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training curves\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "log_file = f'{RESULTS_PATH}/training_log.csv'\n",
        "\n",
        "if os.path.exists(log_file):\n",
        "    df = pd.read_csv(log_file)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Loss\n",
        "    axes[0, 0].plot(df['epoch'], df['loss'])\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].set_title('Training Loss')\n",
        "    axes[0, 0].grid(True)\n",
        "    \n",
        "    # SNR\n",
        "    axes[0, 1].plot(df['epoch'], df['snr'])\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('SNR (dB)')\n",
        "    axes[0, 1].set_title('Signal-to-Noise Ratio')\n",
        "    axes[0, 1].grid(True)\n",
        "    \n",
        "    # Accuracy\n",
        "    axes[1, 0].plot(df['epoch'], df['accuracy'])\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Accuracy (%)')\n",
        "    axes[1, 0].set_title('Watermark Accuracy')\n",
        "    axes[1, 0].grid(True)\n",
        "    \n",
        "    # Learning rate\n",
        "    if 'learning_rate' in df.columns:\n",
        "        axes[1, 1].plot(df['epoch'], df['learning_rate'])\n",
        "        axes[1, 1].set_xlabel('Epoch')\n",
        "        axes[1, 1].set_ylabel('Learning Rate')\n",
        "        axes[1, 1].set_title('Learning Rate Schedule')\n",
        "        axes[1, 1].set_yscale('log')\n",
        "        axes[1, 1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{RESULTS_PATH}/training_curves.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"✓ Training curves saved to:\", f'{RESULTS_PATH}/training_curves.png')\n",
        "    \n",
        "    # Print final metrics\n",
        "    print(\"\\nFinal Metrics:\")\n",
        "    print(f\"  Loss: {df['loss'].iloc[-1]:.4f}\")\n",
        "    print(f\"  SNR: {df['snr'].iloc[-1]:.2f} dB\")\n",
        "    print(f\"  Accuracy: {df['accuracy'].iloc[-1]:.2f}%\")\n",
        "else:\n",
        "    print(\"⚠️ No training log found\")"
      ],
      "metadata": {
        "id": "visualize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Test Trained Model"
      ],
      "metadata": {
        "id": "test-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best checkpoint\n",
        "best_checkpoint = f'{CHECKPOINT_PATH}/best_model.pth'\n",
        "\n",
        "if os.path.exists(best_checkpoint):\n",
        "    print(\"Loading best model...\")\n",
        "    checkpoint = torch.load(best_checkpoint)\n",
        "    ideaw.load_state_dict(checkpoint['model_state_dict'])\n",
        "    ideaw.eval()\n",
        "    print(\"✓ Best model loaded\")\n",
        "    \n",
        "    # Test on sample audio\n",
        "    import librosa\n",
        "    import numpy as np\n",
        "    \n",
        "    # Load test audio\n",
        "    test_audio_path = f'{LOCAL_DATA_PATH}/val/test_audio.wav'  # Update with your test file\n",
        "    \n",
        "    if os.path.exists(test_audio_path):\n",
        "        audio, sr = librosa.load(test_audio_path, sr=16000)\n",
        "        audio_tensor = torch.FloatTensor(audio).unsqueeze(0).to(device)\n",
        "        \n",
        "        # Generate random message and location code\n",
        "        message = torch.randint(0, 2, (1, 16), dtype=torch.float32).to(device)\n",
        "        lcode = torch.randint(0, 2, (1, 10), dtype=torch.float32).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # Embed\n",
        "            audio_wmd1, _ = ideaw.embed_msg(audio_tensor, message)\n",
        "            audio_wmd2, _ = ideaw.embed_lcode(audio_wmd1, lcode)\n",
        "            \n",
        "            # Extract\n",
        "            mid_stft, lcode_extracted = ideaw.extract_lcode(audio_wmd2)\n",
        "            message_extracted = ideaw.extract_msg(mid_stft)\n",
        "            \n",
        "            # Calculate accuracy\n",
        "            msg_acc = ((message_extracted > 0.5).float() == message).float().mean().item() * 100\n",
        "            lcode_acc = ((lcode_extracted > 0.5).float() == lcode).float().mean().item() * 100\n",
        "            \n",
        "            print(f\"\\nTest Results:\")\n",
        "            print(f\"  Message accuracy: {msg_acc:.2f}%\")\n",
        "            print(f\"  Location code accuracy: {lcode_acc:.2f}%\")\n",
        "    else:\n",
        "        print(f\"⚠️ Test audio not found at {test_audio_path}\")\n",
        "else:\n",
        "    print(f\"⚠️ Checkpoint not found at {best_checkpoint}\")"
      ],
      "metadata": {
        "id": "test-model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Download Results"
      ],
      "metadata": {
        "id": "download-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip checkpoints and results\n",
        "!zip -r checkpoints.zip {CHECKPOINT_PATH}\n",
        "!zip -r results.zip {RESULTS_PATH}\n",
        "\n",
        "print(\"✓ Files zipped\")\n",
        "print(\"\\nYou can download:\")\n",
        "print(\"  1. checkpoints.zip - Trained model weights\")\n",
        "print(\"  2. results.zip - Training logs and plots\")\n",
        "print(\"\\nOr access them directly from Google Drive at:\")\n",
        "print(f\"  {DRIVE_PATH}\")"
      ],
      "metadata": {
        "id": "download"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Download directly from Colab\n",
        "from google.colab import files\n",
        "\n",
        "# Uncomment to download\n",
        "# files.download('checkpoints.zip')\n",
        "# files.download('results.zip')"
      ],
      "metadata": {
        "id": "download-direct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Push Code Updates to GitHub (Optional)"
      ],
      "metadata": {
        "id": "push-github-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you made code changes in Colab, push them back to GitHub\n",
        "\n",
        "# Configure git (first time only)\n",
        "!git config --global user.email \"your.email@example.com\"\n",
        "!git config --global user.name \"Your Name\"\n",
        "\n",
        "# Check what changed\n",
        "!git status\n",
        "\n",
        "# Add, commit, and push (uncomment to use)\n",
        "# !git add .\n",
        "# !git commit -m \"Updated training code from Colab\"\n",
        "# !git push\n",
        "\n",
        "print(\"\\nNote: You'll need to authenticate with GitHub token if pushing\")\n",
        "print(\"Generate token at: https://github.com/settings/tokens\")"
      ],
      "metadata": {
        "id": "push-github"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Pull Latest Code Updates (Optional)"
      ],
      "metadata": {
        "id": "pull-github-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you updated code on your local machine, pull latest changes\n",
        "!git pull origin main\n",
        "\n",
        "print(\"✓ Code updated from GitHub\")"
      ],
      "metadata": {
        "id": "pull-github"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Keep Session Alive (Optional)\n",
        "\n",
        "Run this JavaScript in your browser console to prevent disconnection:\n",
        "\n",
        "```javascript\n",
        "function KeepAlive() {\n",
        "    console.log(\"Keeping session alive...\");\n",
        "    document.querySelector(\"colab-connect-button\").click();\n",
        "}\n",
        "setInterval(KeepAlive, 60000);\n",
        "```"
      ],
      "metadata": {
        "id": "keep-alive"
      }
    }
  ]
}
